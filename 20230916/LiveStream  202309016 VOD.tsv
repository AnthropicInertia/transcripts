start	end	text
0	29000	I just spent the whole day pretty much bringing up my age-old blog site.
29000	46000	Last I had worked on it was I had moved it to 11ty because I wanted a good enough markdown to a good enough more text-focused site.
46000	54000	And then I have been trying, what I've been saying that I want to get back to writing.
54000	64000	So there was something very small happened at work so I started working with these people because it was the end of the project.
64000	70000	And one of the things that we are currently doing is figuring out deployment plans.
70000	91000	One of that was versioning strategy and I was like, at least let me write whatever we decided there because where it began was it started as a small tweet on Mastodon trying to just write the format that I had decided.
91000	100000	Then I needed to write another paragraph. Then I exceeded Mastodon's text limit. Should I break it down into multiple posts?
100000	109000	At this point, it makes sense to just write it in markdown on that blasted site where I have not made updates in years and put it there.
109000	116000	Then when I went to put it there, I first did it. It's connected to Versel so you need your deployment.
116000	124000	Then I log into Versel and I see a bunch of build failures. Sorry, sorry, it did not go through. It got blocked so I logged into Versel and I saw build failures.
124000	136000	And turned out it was set to Node.js 12. So Versel has deprecated Node 12. So this entire day was that thread.
136000	143000	And then it was, I have done this, I have done that. I might as well sit with the recording and start writing.
143000	149000	Okay, now that I have written, I might as well put it on the website. Now that I have put it on the website, I might as well do this.
149000	156000	So that's what I was doing till 1758.
157000	161000	Actually good, pretty good.
161000	179000	We are live. So yeah, I also have to do something very similar and I have written more, I started writing more amount of microblogging frameworks than actually blogging.
179000	187000	Every time I come up with this, this one doesn't fit me, I need to write something. There are so many names, FLOG.
187000	193000	The last one was named FLOG.
193000	202000	But yeah, I appreciate somebody at least putting things out there instead of just doing the procrastination behind it.
202000	208000	Even just for five years.
208000	216000	But what I mean is today is a historic day, even if it is the only historic day for the next four years.
216000	221000	Makes sense, makes sense.
221000	227000	So I was thinking about what you said and kind of trying to build up the idea.
227000	242000	So here's a thought. We have the right ideas, we do the right things, but don't, like we get, because we are too early to the party, we get lukewarm feedback about it.
242000	246000	And we don't stick around when the party actually kicks in.
246000	253000	We kind of, before that, shit this sucks and I'm going to go home and we just leave for home.
254000	258000	That ends up happening.
258000	262000	I don't have to explain that part, right? You agree that happens.
262000	268000	Now if we explain it will be for the audience and for the record, like FDR.
268000	272000	So I'll come back to the explanation part.
272000	280000	Like when those things happen, Applet is a good enough example, the AI, the things that we predict, this is where things will go.
280000	285000	These are the things we should build that also includes like, what do you call it?
285000	294000	The online communication platforms, Groupone and all, like very efficiently adopting WebRTC, seeing the potential in it.
294000	298000	All those things, we did it early, did it in advance.
298000	304000	It actually struck a chord with people who cared, but not with the mass.
304000	310000	It was not sustainable in that sense, that it wouldn't generate revenue immediately.
310000	319000	But instead of sticking out with that, we kind of like, ah, people just don't understand, let's do something else that is fun and interesting.
319000	321000	We kind of went through the loop of that.
321000	326000	I was thinking that that might again be the case, unless we are being mindful about it.
326000	340000	And this is a platform where, first time in human history, people are actually having discussions or interactive way of communicating.
340000	346000	Just basically not just one to many kind of communication, which has been the entire history.
346000	349000	Somebody tells you something and you do it, instead of that.
349000	361000	Now, I think my audio was still pretty screwed up.
361000	375000	So now, through those podcasts, audio books, like the comments in the video platforms, as well as the response videos like on TikTok and everything,
375000	384000	there's like interactivity between where people are getting their information from and sharing it, bouncing it right back at them.
384000	392000	And that is happening. That is actually huge from a potential perspective, from seeing a potential like what matters, right?
392000	402000	First time somebody like marked something on a card, something on a rock, it was not something that like it was not profound.
402000	408000	It was not really something that you would frame it and put it on a wall.
408000	415000	But it is something that you would frame it and put it on the wall for the sheer potential of transcending information through time.
415000	423000	Similarly, the discussion platforms that are happening that is like not one-dimensional, bidirectional discussion that is happening,
423000	433000	people communicating with the podcasters and stuff, that is going into a direction where I see a lot of people are setting up the base,
433000	442000	creating that ecosystem, which we can leverage from and bring in the discussions that people are yet not having.
442000	452000	We are having these discussions and we also think that, oh, maybe people are not interested about it or people are probably not going to understand it or whatever that is.
452000	463000	But instead of doing that, how about we give our best shot at making it available and whatever happens, happens.
464000	476000	My hypothesis is if we stick around with that and spend a good enough amount of building the backlog of what are the things that we want to talk about,
476000	485000	what are the things that we have at hand and the practice of it, then at some point when people have discovered it are coming along for the journey,
485000	496000	we will have a solid repository of stuff to show as well as solid grasp on the presentation of the topics as well.
496000	501000	And we can take it somewhere. It can become more than what it is now.
505000	512000	With that said, what are you thinking about this? Quick thought, it was just like I was thinking about half an hour before.
513000	529000	So this is a pattern that I anyway have found and I totally agree that the challenge with our work hasn't been really that we don't have interesting things to work on.
529000	537000	But I just want to say two things. One is my experience this morning, what I just narrated, how I got into fixing the site.
537000	545000	The only thing we need to do is look at something long enough, the way change, the way we trigger change or we work.
545000	549000	Sorry, that's like my cat's fur getting into the fans.
554000	564000	Basically, the way we have worked is if we look at something long enough, start seeing the cracks, start seeing the gaps in that and then we would like to fix that.
564000	569000	So this entire journey with Applet has been exactly that.
569000	577000	But the problem was that there were too many things to fix and we were like falling through the rabbit hole, not hitting the bottom.
577000	585000	By the time we hit the bottom, it kind of timed out. It was time to go home at that point and many other things at the same time.
586000	599000	But the point is that bottom, that journey, when I look back at that, there is a certain deconstructionist approach that I'm applying to that memory.
599000	613000	That how did we go? Where did we go? It was as if the quest to where it landed on unicorn, really, which was kind of breaking down to a certain set of fundamentals.
614000	626000	And I think that part is still valid as an area of research, as an area of research.
626000	633000	But the second thing here is that I have been already watching the last two videos that we have recorded.
633000	648000	This being chapter three in this discussion, and I see us intentionally or unintentionally overlapping topics, like the same things that we had discussed last time, that comes in through another area.
648000	656000	So if I was to archive this, what I found was there is one, of course, a narrative of as we spoke in the order of things.
656000	671000	But then if I blend that into like an encyclopedia or a knowledge base, so to say, by broad questions and topics, it turns out that we have a lot to say over time about the same thing.
671000	675000	And aggregating that would be very interesting.
675000	687000	So what I want to do really is with these discussions, I want to pipe this through to first us like speech to text engine, populate the basic.
687000	694000	And I mean, it's semi-intelligent speech to text, not just basic Python speech to text.
694000	697000	But that is where the AI part comes in.
697000	705000	The link that I shared with you, I had only gone through chapter one.
705000	712000	And as I kept on listening, I was also listening to last week's recording yesterday.
712000	717000	I was like, wait, didn't we discuss on day two and I'm watching day one?
717000	732000	And then I went to day two and it seemed like in day two, we have discussed everything about the topic, except the part that was touched on day one with some just common bridges, which means there is value in creating this union of sets.
732000	734000	And these topics are emerging.
735000	741000	What I mean to say is that whatever we repeat, whatever beers repeating in our discussions is something that we want to get back to.
741000	752000	And those should be the topics, which brings me back to that loop that I had said on the first chapter that if we are looping, then that is worth recording.
752000	757000	And that itself then goes on to form broader discussions.
757000	774000	So I totally agree in the sense that I think in the future, let's say even a year down the line, we could be looking at what we have done and trace it back to something like chapter two, chapter three, chapter four of the discussions to find that pathway.
774000	781000	This is good. We just follow where curiosity is leading at this point.
781000	783000	I think it's naturally emerging in a very nice way.
783000	786000	So when it's a curiosity time and whatever spark.
786000	787000	Yeah, yeah, yeah.
787000	801000	So I, so in that sense, let's not rush into packaging it and packaging is in sense like to make it something of a brand or anything immediately.
801000	806000	Let's go through the same process that we are doing right now with some patterns will emerge.
807000	814000	What you're talking about like the horizontal and the vertical interpretation of the things like we're talking about, like having a chronological.
814000	818000	Okay, we talked about these things today that think to the day after.
818000	828000	But also, if we look at from the perpendicular view, we talked about this part of this topic this day, and that part that day, and combine that as the topical discussion part.
828000	843000	So I have a wiki deployment. If that helps, if you want to also interpose as in, what do you call it, make it topical in that way order that also can work that way.
843000	846000	Yeah, I think that is phase two anyway.
846000	850000	Okay, I see. Cool.
850000	852000	Where was I going with this?
859000	867000	So, I was talking about how, where was I going with this?
867000	870000	I think I had a thought and it vanished. It popped.
870000	875000	Okay, forget it for the time being.
875000	881000	I think I understand what you're saying. I agree. Let the pattern emerge naturally.
881000	886000	Oh, the other part of it was about the speech to text part we talked about, right?
886000	894000	Speech to text, yes. So, there are a couple of services.
894000	901000	None of them are very cheap, cheap enough, as in, but...
901000	912000	I mean, I would measure it in my time, right? I mean, at this point, if I take three hours to get to a transcript, what is the cost of my three hours worth of work? I have a very clear idea.
912000	916000	I think it's more than that. If so, I'm willing to try.
916000	927000	It costs in thousands of minutes, and it's going to be $0.1 or something like that per session, ideally, something like that.
927000	931000	Yeah, I mean, anything under 15-20 is good enough.
931000	938000	Exactly. So, the better ones would be Assembly AI and second would be Deepgram.
938000	946000	And if we don't want all of that, if we just can run...
946000	954000	Do you have a GPU right now? Yes. So, which one did you get? Did you get the Intel Arc or did you get the...
954000	961000	I have a 4060. Okay. So, in that case, also, it's an RTS GPU. You can run the models.
961000	966000	So, those server services are also running, actually, the Whisper, the OpenAI Whisper.
966000	975000	So, if you run OpenAI Whisper, the JAX version, so I'll send you the details, right?
975000	980000	So, in that case, you can just basically run it on your system and get the result.
980000	985000	Yeah, so, I wanted to use the same opportunity to also learn at the same time.
985000	996000	The reason I created that space on my blog was I'm now like, I want this to be filled in this format, except I don't want to be doing it.
996000	1003000	I want a script, help somebody do it.
1003000	1010000	But there was another pattern that I noticed by watching the last two recordings.
1010000	1023000	And that is compared to the last times we discussed this, there is a lot of higher order maturity in our thinking, because we have spent more time, both you and I.
1023000	1032000	Like earlier, what used to be vague jumps across the chasm, now they are like very well identified landing points and like we have traced.
1032000	1044000	So, what I mean is that certain things are very well formed and putting them together will probably be quicker than, let's say, it was last time.
1044000	1054000	What I again want to do is make sure that those inflection points are captured.
1054000	1059000	It's very much like watching two galaxies merge.
1059000	1065000	It's kind of that dance. You know it won't clash, it will just flow through each other.
1065000	1074000	The important thing is locking around that, like what you had said as twin stars orbiting.
1074000	1079000	I think it is looking like two galaxies currently merging and would then begin orbiting.
1080000	1086000	So, yeah, so last day we started talking about something.
1086000	1089000	Do you want to continue with that or do you have some other topics in mind?
1089000	1095000	OK, let's try to go for that. By the way, I posted the link about the whisperjacks.
1095000	1103000	So, if you can run it on your system, I think you will get the transcriptions for free, essentially.
1103000	1108000	Right, cool.
1108000	1123000	So, I was trying to make a criticism about dialectics, as in the entire process of dialectic, the dialectic process itself.
1123000	1132000	I was not able to put a finger on exactly where my discomfort comes from,
1132000	1140000	but finally I realized it from a concept called PID controllers.
1140000	1143000	Did I expand on this? I didn't.
1143000	1146000	OK, so let me share my screen then.
1153000	1175000	Can you see it?
1175000	1190000	I can't hear you, so you have to say yes or no.
1190000	1192000	I can see, I can see.
1192000	1197000	OK, fine.
1197000	1202000	So, this is a controller theory that is used pretty much everywhere.
1202000	1208000	You are trying to stick a landing, essentially, frankly speaking.
1208000	1217000	That includes the previous attempt of landing the Chandrayaan-2, essentially, the rover.
1217000	1223000	So, point being, there are three aspects to that control theory.
1223000	1229000	One is the proportionality control, second is the integral control, and third is the derivative control.
1229000	1235000	What do they do?
1235000	1243000	I'm not going to the maths part of it, just keeping it very straightforward and visual interpretive.
1243000	1254000	So, if you are trying to get somewhere, the intent of going there is, let's say, higher when you are not there,
1254000	1257000	further away from that position, the set point you are.
1257000	1260000	So, let's say, for example, this is your initial position.
1260000	1263000	This blue marker is your set point where you want to go.
1263000	1269000	Further away you are, the more intention that you have to get there.
1269000	1276000	But as closer you go, you have less and less intensity to get there,
1276000	1278000	because if you keep that intensity, you will cross over, right?
1278000	1280000	You will just shoot through.
1280000	1284000	So, you have to reduce that proportionally.
1284000	1288000	That's the proportionality part.
1288000	1291000	You can identify that as an echo chamber.
1291000	1294000	This is the thesis part.
1294000	1302000	Now, there's a drawback to that only using proportionality.
1302000	1309000	As closer it gets, there's a paradox with that as well.
1309000	1313000	It says you cannot reach the other end of the room diagonally,
1313000	1322000	because the arrow does not reach the target, because it has to get to the halfway point,
1322000	1325000	and then the halfway point, etc.
1325000	1328000	When actually you reach the other end, you never reach.
1328000	1330000	So, that actually happens mathematically here.
1330000	1334000	You asymptotically approach it, keep on approaching it, you never reach it.
1334000	1339000	So, in order to challenge that, you need a mechanism
1339000	1346000	that looks back at what the date is, the date it needs to pay,
1346000	1352000	and then it drives the proportionality up in order to reach that goal.
1352000	1353000	That's the integral part.
1353000	1360000	What it does is that it continuously checks how far behind we are from reaching the target,
1360000	1367000	and it keeps on adding an extra term to it.
1367000	1369000	So, the second part of that.
1369000	1375000	So, when you are getting closer, the proportionality of this value becomes smaller.
1375000	1377000	This value takes over.
1377000	1385000	The challenge there is the integral part does not have a self-correction mechanism for itself.
1385000	1389000	So, what ends up happening is that it shoots through, goes to the other end,
1389000	1394000	then basically has to come back again, because that part of self-correction is there.
1394000	1398000	So, when it realizes that, hey, I'm way off,
1398000	1403000	when the latency of looking back catches that, hey, I'm way off,
1403000	1407000	that's when it tries to self-correct itself and tries to go back.
1407000	1413000	But it results in a harmonic, as in oscillation, like it's basically a ringing,
1413000	1418000	where it never, again, it does not reach the set point.
1418000	1426000	It oscillates around the set point because it always has some amount of delta time
1426000	1431000	to look back on to identify that, hey, I need the correction, I need to correct myself.
1431000	1438000	That's where the derivative, so by the way, this integral term, you can look at it as the antithesis,
1438000	1445000	the term that tries to correct the proportionality, the echo chamber,
1445000	1449000	by bringing in the counter-argument and fixing the part.
1449000	1455000	The only thing is that there's also the exact same kind of latency that gets in.
1455000	1458000	And that's the part we actually talked about before,
1458000	1466000	is that we always end up overdoing any kind of social changes that needs to happen
1466000	1470000	when the discussion comes in, in a generation or half,
1470000	1478000	we basically overdo it and then we have to, again, go the other direction a little bit.
1478000	1484000	So, that's what ends up happening with integral term.
1484000	1487000	Now, what to do about this?
1487000	1491000	Another way to approach this is that the derivative term.
1491000	1498000	So, the derivative term approaches in a way that it has very little to no effect at all when starting,
1498000	1506000	but it checks for the delta it needs to reach around the set point and dampens the response,
1506000	1516000	sorry, basically the value by adding or subtracting the corrective term, that is, look ahead.
1516000	1522000	So, as integral part was look back, like how much we have not achieved what we should have,
1522000	1532000	and adding it to it, derivative terms like how much, how strongly are we gonna cross the set point
1532000	1537000	and dampening the response by that, and if that is not the case, then letting it happen.
1537000	1543000	Like, go fast if you are not approaching, but slow down if we are approaching that point.
1543000	1548000	In that sense, what it does, it basically helps us stick that landing.
1548000	1560000	Depending on the values, you still have that not, this animation would be kind of appropriate to see how it ends up happening.
1560000	1568000	There are more. So, basically what ends up happening in the ideal state is it goes straight like this,
1568000	1575000	asymptotically kind of gets closer and then touches it, and depending on the parametric values,
1575000	1580000	you get the landing, how closely it sticks the landing, right.
1580000	1587000	So, hopefully that made some sense. I'm not sure how much it came out in the diagram.
1587000	1601000	My point is, we don't have the third aspect in our, what would be an umbrella term for what dialectics is about,
1601000	1606000	or what dialectics tries to fix.
1607000	1618000	So, that part, this would be the third part that we need to add, which I'm calling it the hypothesis part,
1618000	1624000	which is look ahead, where do you want to stick the landing, looking ahead for that,
1624000	1629000	and then correcting the other two sides of things like thesis and antithesis,
1629000	1634000	gets corrected by the hypothesis and then sticks the landing, where it needs to be.
1634000	1641000	So, there are lots of like, I don't have worked for a lot of things, maybe because I didn't do enough reading about it.
1641000	1649000	This is kind of an original thought. So, I need a lot of supporting elements to build it up into a theory.
1649000	1656000	I'm done saying the things that I wanted to say. I am looking for the criticism on this part.
1657000	1665000	Yeah, I'm not sure you're going to get much in the way of criticism as much as a critique.
1665000	1673000	So, I do think, so when I said landing, I pretty much had something similar in mind,
1673000	1678000	though not, this is a good mathematical demonstration of what I was talking about.
1678000	1683000	And now I realize what you said last day when you said that hypothesis is the thing that's missing.
1684000	1694000	So, that connects back. And I do agree that in the sense that if we are to plot the rate of change of topic,
1694000	1698000	which is also what I was saying, that if we look long enough at something,
1698000	1707000	so what is worth looking long enough if something is appearing in the vision, then stay with it, slow down your approach,
1707000	1714000	and then invariably you're going to overshoot it a bit, then come back and land.
1714000	1723000	So, I think that there are multiple hypotheses on which I think we both are operating.
1723000	1730000	At least that is what I meant by a certain higher order thinking that has already happened.
1731000	1742000	Sorry, the reason we are not shooting off target really is that some of those targets far enough or fundamental enough have been identified.
1742000	1747000	So, I think it's a matter of letting down some of those hypotheses,
1747000	1757000	then discovering the hypothesis or articulating the hypothesis would probably be the primary focus of these discussions
1757000	1762000	each time with the aim to land the hypothesis in that sense.
1762000	1771000	So, your hypothesis is the blue mark and in the process some things will be things that we'll find solved.
1771000	1777000	Hypothesis is not the blue mark. If you go back to Hegelian interpretation,
1777000	1784000	the reason he came up with this is that the Father and the Son and the Holy Spirit, the Trinity,
1785000	1792000	he was trying to kind of symbolize the Trinity, which also Freud did with Ego, Superego and all these things.
1792000	1798000	So, that was kind of something everybody was trying to connect back with the theology of that time,
1798000	1809000	which I already identified or symbolized that there's a Father and the Son and the Holy Spirit and they form the Trinity.
1810000	1822000	From Hegel's interpretation, he said those three things like the thesis, antithesis and synthesis were those three things.
1822000	1835000	My point is that's not. The synthesis is the Trinity and the Spirit has to be the hypothesis.
1835000	1845000	The Son is the Id or the Son is the proportionality, the Father is the antithesis or the superego.
1845000	1855000	But the thing that lands the landing, that is the hypothesis part, that you need, that's the Spirit, that's the ego,
1855000	1865000	that's the part you need to land. And overall, they connect back as a Trinity. Overall, they connect back as the synthesis.
1865000	1874000	So synthesis is not complete without the hypothesis. What ends up happening is that we have not integrated that as a process.
1874000	1889000	In our, even till contemporary, we kind of look down on somebody hypothesizing something as you don't have solid data for it, right?
1889000	1897000	My point is solid data is only possible as an option for looking back, that integral aspect of things.
1897000	1906000	For you, if you want to stick the landing and not overdo anything, not do the damage, the only way to do that is look ahead.
1906000	1912000	And for that matter, you cannot have solid data. You need to have the differential part aspect of the thing.
1912000	1920000	So which is where the third aspect, the Spirit or whichever way you want to interpret is, that needs to happen.
1920000	1926000	So the overall thing comes as the Trinity. Overall, that comes up as the synthesis.
1926000	1936000	But I think that those three things, that parts of the Trinity are that thesis, antithesis and the hypothesis.
1936000	1944000	Together they make the synthesis, or together they should make the synthesis, which is much more nuanced than the previous approach.
1950000	1960000	I mean, in some sense, we are talking epistemology, so why not?
1960000	1971000	I should read this, as in I haven't gone through this.
1971000	1980000	So the epistemology that you would find in some of those Eastern traditions breaks down those concepts into further stages of proof.
1980000	1989000	So you look at Buddhist epistemology, you look at Nyaya epistemology, Shankar epistemology.
1989000	1994000	Shankar is probably the one who simplifies it in some sense, but it's Doito.
1994000	2002000	So it talks of two materials, which tries one nation, one election kind of strategy.
2002000	2012000	Everything is one. But Nyaya does this very interesting thing where it was a practice.
2012000	2020000	Now why I shared this, as opposed to Hegelian dialectic, is they are talking about the same things.
2020000	2032000	These are very, very strong similarities. But these were traditions who ceremonized their usual exchanges.
2032000	2039000	These were philosophies born out of people actually discussing, questioning each other, coming to the truth.
2039000	2045000	That is where Torco comes from. As it happens, if you look at the list,
2045000	2055000	stage number eight of the 16 categories is called Torco or hypothetical slash suppositional reasoning.
2055000	2062000	So Torco Corona is basically somebody says don't hypothesize. If you hypothesize, you are already on stage eight.
2062000	2068000	You're not far enough from actually achieving knowledge.
2068000	2078000	But these were basically the 16 categories. Now what these categories mean will leave that to coming outside of this entire thing.
2078000	2086000	But if you just scroll down a bit, like the overall epistemology, that you have perception,
2086000	2092000	and within which you have determinate, indeterminate, then you have onuman, so inference.
2092000	2102000	And these systems also standardize in some sense or formalize certain lines of inquiry that Western philosophy just ignores as voodoo.
2102000	2108000	But turns out there is enough, enough details in this schools of knowledge.
2108000	2119000	And you will find yourself very familiar with those. All it struck me when I read the first demo that this is how they have categorized.
2119000	2130000	I know all of these sensations. It's like they have presented me a curated, ordered structure to that exact chaos.
2130000	2142000	Now of this, these are like these are degrees of formation of knowledge. So Proman, which is the strongest.
2142000	2148000	So it says that before perception, inference is not as strong, but good enough.
2148000	2158000	Then you have upoman, which is comparison, which is, again, not that analogy, which is what you get to if you can't infer.
2158000	2163000	Then you have shop, though, which is testimony somebody else's words.
2163000	2169000	But the interesting thing is you can start this process outside in.
2169000	2183000	And if you then look at these three stages, you kind of again reach that sort of Trinity, because the hypothetical reasoning happens when you are discussing or when you are like that is where the dialectic comes in.
2183000	2195000	So hegel's hegelian dialectic and torco in there are kind of the other things you would apply to get to that hypothetical supposition.
2195000	2201000	But all I'm saying is that you're on the right track. This is and that was a bit patronizing.
2201000	2209000	But you're on the right track in the sense that I would just say that hegel is good.
2209000	2221000	Keep this on the other side and and keep the Buddhist epistemology on the other side, because what that says at its fundamental nature is you got to try things to believe it.
2221000	2226000	But if you don't get to try, what do you do?
2226000	2230000	You have to assume you have to imagine.
2230000	2233000	So basically, these all are people.
2233000	2239000	If you read those treatises, you find these people sitting randomly and asking what if questions.
2239000	2249000	Very little resource, which is why like my respect kind of goes out and goes for those people who have thought about these things with so little resources.
2249000	2253000	Because they couldn't have for the even the best they tried.
2253000	2258000	They couldn't have known all the other things that have happened, all the other people who are thinking the same terms.
2258000	2265000	So I kind of feel that we are so lucky that I can have a day job and also like do this for fun.
2265000	2268000	Right. Which is insane.
2268000	2277000	For many people, they had to live their life as essentially the way of living in order to even get any anywhere closer to this.
2277000	2281000	Which is also like I should not take this for granted, but yeah, it opens up.
2281000	2284000	But there is an earlier of that life.
2284000	2288000	I came to that. So this was my thought when I first studied this.
2288000	2294000	And this was for second year, sorry, first year, second semester of philosophy.
2294000	2301000	And my first thought was these people built so much exactly these words without so little.
2301000	2304000	And this was 2009. And I was like, if they had the technology today.
2304000	2314000	So we'll keep on saying this. But then as I learned more, I realized that these technologies, these are technologies to the point of understanding knowledge.
2314000	2319000	You apply these things to a knowledge based to creating a knowledge system.
2319000	2324000	And you don't have to be a product manager. These people have been your product managers.
2324000	2328000	You just let it implement what they're saying in these stages.
2328000	2339000	And because they work with such small data window, their computation is very resource conservative, not wasteful at all, essentially.
2339000	2353000	Which means the computations have been broken, broken, broken down to their smallest forms where they are understandable, then logically build up as a foundational system and highly technically interconnected sets of work.
2353000	2359000	So basically, I'm saying they were the product managers like epistemology is product management of knowledge.
2359000	2364000	Yeah, I see that. I see that. I see that form, essentially.
2364000	2379000	And I think one of the things I one of the hypothesis that I have been operating on is what what framework these people had created can be implemented using the technology that we have today.
2379000	2385000	Without the individual, because a lot of this practice then went on to the Sadaq.
2385000	2398000	So you don't then have to be the Sadaq. You can if you can outsource, you know, to the Babas that you have always wanted to outsource these decisions to.
2398000	2409000	Why not just like try a different Baba, a Baba that actually understands these things has been built with some like these technologies in mind.
2409000	2420000	But anyway, going too vague, what I mean is that I believe it is possible to build a knowledge base that employs these systems of knowledge and then, you know, build those views.
2420000	2427000	So given the same set of events, can I have a Hegelian dialectic view of the events?
2427000	2440000	Can I have a new view of the events, which are just different queries, different structured queries producing different kinds of data structures out of the same fundamental thing that you were seeing?
2440000	2443000	I am also seeing which is the nature around them.
2443000	2453000	Right. So that way, this is those all those previous prior works, they're basically stepping stones to go forward, go further.
2453000	2455000	Right. Absolutely. Yeah.
2455000	2471000	So that's how I'm seeing it. There are lots of these, these things, all these things should be kind of kept as like, okay, in the Appendices or the References section that, hey, this builds on top of these things.
2471000	2477000	In order to go forward, you cannot just have a solution and as a capsule and just eat it.
2477000	2485000	Basically, if you understand what are the parts it builds on top of, that gives you a better mileage.
2485000	2495000	So I think all the prior attempts, because the best they could do is build in the present by looking at the past.
2495000	2503000	That was the best approach that they could have taken, like very definitively, because we have to identify this thing as well.
2503000	2510000	What we are doing now is taking over of the derivative part.
2510000	2517000	Think about because we're closer to the set point. That's when the derivative takes up, like picks up the pace, because that's where it starts mattering more.
2517000	2518000	Right.
2518000	2521000	So we are bringing in that part.
2521000	2531000	And so far it hasn't been used as much because so far that that part of the equation was very miniscule and ignorable.
2531000	2536000	More what mattered mattered was the proportionality and the backlog of like, hey, we need to fix this thing.
2537000	2542000	Now, where to get to, we have a very closer view of because we are kind of reaching that.
2542000	2550000	If for the lack of a better set point, let's say superintelligence is the set point that we are looking at.
2550000	2556000	We are kind of approaching that closely enough that we need to if we don't stick the landing.
2556000	2562000	There are a lot of people are talking about what the dangers that like involved with that.
2562000	2565000	So point is now it starts mattering.
2565000	2571000	Now we are bringing that aspect, that part of the equation up and try to stick the landing.
2571000	2576000	I don't see the previous approach as the wrong or false or something.
2576000	2579000	It's just at that point, that's the best they could have done.
2579000	2583000	And at that point, those two are the things that mattered more.
2583000	2590000	Now that we're starting to matter the other way, let's make it more comprehensive and use the other term.
2590000	2599000	I just want to destigmatize the usage of hypothesis because if you look at it from even a school or childhood,
2599000	2605000	like if or even especially in we are data driven, whenever people say that,
2605000	2611000	what they're trying to nullify or invalidate is that somebody who is pitching an idea
2611000	2619000	that they don't yet have solid data for and to demotivate them from going ahead and gathering the solid data for it.
2619000	2622000	Right. So that's what ends up happening.
2622000	2628000	I want to destigmatize that part, that aspect of the entire discourse when that happens.
2628000	2636000	And overall, push it out into the system like the general side search or whatever you call it.
2636000	2638000	Is that the pronunciation?
2639000	2651000	To make everybody come to the conclusion that, hey, it is from temporal perspective,
2651000	2654000	we cannot only look at the present and the past.
2654000	2662000	Future matters just as much because the other parts of the discussion that we'll eventually come to,
2662000	2669000	where if you look at the actualization of the universe, it basically is a temporal loop in a sense.
2669000	2673000	It's like a rubber band. Where is the ending?
2673000	2680000	You cannot find where the ending or the beginning is if you start seeing the whole thing as a temporal loop.
2680000	2686000	So it is relevant to be mindful about the whole directionality,
2686000	2692000	the spline of time and not only just look back on one direction.
2692000	2695000	Yeah. Right.
2695000	2698000	So this is one of the topics that I want to kind of like build upon.
2698000	2705000	I'm pretty sure like we touched on this like two episodes like last time I talked about this.
2705000	2709000	This time I'm showing some of the data about this.
2709000	2717000	I'm pretty sure that there will be more terms and all those things that I will come up with and start enriching this particular topic.
2717000	2721000	This is going to be one of the topics.
2721000	2729000	Yeah. So let's put a pin on that and move forward with other things that we may want to talk about.
2729000	2735000	I have a lot of other things, but do you have anything else to talk about this?
2735000	2754000	I think this deserves a bit more elaboration just for the sake of.
2754000	2756000	Yes, what happened?
2756000	2762000	My headphone decides to go to sleep from time to time. It's grown old. It's like I have to go to sleep.
2762000	2766000	I don't think you are speaking through as in the mic change.
2766000	2771000	Essentially, the mic source changed.
2771000	2773000	Yeah, should be better now.
2773000	2776000	Yeah, it had I had reconnected, but it has switched back.
2776000	2779000	Yes. Anyway, I was saying that this topic deserves a bit more elaboration.
2779000	2789000	Therefore, we move on to others because there is some fundamental that this connects to to what I have been working towards and thinking.
2789000	2793000	And it's sort of right this time, right?
2793000	2803000	So the hypothesis that I mentioned that it should be possible to take some of these tools for mass consumption.
2803000	2806000	And when I say mass consumption, let me rephrase that.
2806000	2812000	I mean, regular consumption for myself and to those I want to share the information with.
2812000	2816000	I'm looking at the inside out network.
2816000	2827000	And for the same reasons that atoms form, then connect and the connecting force being a sort of gravity.
2827000	2842000	So what I see this possible like being possible to do is pretty much the same thing that if you look at Automarge, that local first project.
2842000	2858000	In some sense, my approach to knowledge management is kind of similar to their approach to dev tooling, where they say that if developers have built enough tools to make their life easier, software developers specifically,
2858000	2865000	the sort of debugging and things that don't exist for other technical professions.
2866000	2879000	Besides software design, because we use line based things and their premises to bring the same kind of things that clearly serve some small people are benefiting out of implementing within their domain,
2879000	2890000	bring those concepts and apply to a set of baseline fundamental tools that can also apply to other domains of creative work.
2890000	2896000	And what I'm trying to say here is that I feel like my approach to I mean, they have explained it in a certain ways.
2896000	2913000	I'm just using that analogy that I feel like there are all these different epistemological theories, which if you just look at them as investigations, queries and frameworks to understand, categorize, dissect knowledge.
2913000	2923000	I see different demos, those lenses that I had mentioned, right? Lenses of looking at reality are what each of these frameworks are.
2923000	2926000	So what happens? Instagram filters.
2926000	2945000	Now here is the key part. Each of them start telling you that there is a certain moksha, nirvana, whatever, orgasm, whichever stage, like there is a certain stage that you can reach if you follow these certain processes.
2945000	2958000	Now, if you break down those processes, study deeper, you'll see that they are very logical, very one after the other, very well structured journey, meaning that it is possible to reach that moksha.
2958000	2963000	And it's like a definition of done, that there is a clear definition in each of these traditions.
2963000	2969000	What do they mean by their equivalent enlightenment is the word that I was looking for.
2969000	2973000	What is the equivalent enlightenment in their traditions? What does that mean?
2973000	2991000	And as it happens, it is a lot of analytical data processing, sensory data processing, building up maxims, building up more and more compressed knowledge, which some of them also talk of the neoteny that you mentioned.
2991000	3000000	How do you get a crystallized knowledge but to retain the neoteny? That is a sort of moksha state or pre-moksha state for most of these systems.
3000000	3017000	But then my question, the my what if scenario is, what if we could codify these, do the computations and just try to reduce the time it takes to arrive at that moksha in maybe a scoped way.
3017000	3025000	So specific intelligence as opposed to general intelligence.
3025000	3044000	But it is possible to arrive at moksha, which is now if I just basically try to pass a data set through the kind of filters, they have talked of practices, they have talked of practices or loops, filters are well, like stages are filters.
3044000	3050000	You have to pass certain rituals to get somewhere or go through certain commandments.
3050000	3052000	It's a very well articulated system.
3052000	3058000	So if you can think of a flow, you would be able to map out each of these into very complex flows.
3058000	3069000	And if you then think of it from that flow based programming or functional programming concept, you should be able to build higher order functions, which basically form these.
3070000	3082000	And my hypothesis there is with or without AI, it should be possible to build the structural manifolds, which provides a sort of variability into existing data.
3082000	3103000	And then one of those views is like just a model that understands the AI way of looking at knowledge, which means it can categorize based on everything you throw at the knowledge base that these were the testimonies that you had heard.
3103000	3105000	These were the hypothesis that you had conjectured.
3105000	3107000	These were the inferences that you had built.
3107000	3112000	These were the experimental perceptions that you have had and thus this is the knowledge that you have gotten.
3112000	3116000	And these are, you can trace these back to these proofs with this much certainty.
3116000	3120000	The probability of knowledge happening is baked into these systems.
3120000	3122000	So not everything is certain.
3122000	3126000	You can be, you can get conflicting inputs.
3127000	3152000	So basically that is basically that some might be saying but it is probably a lower confidence score compared to you have touched it and you have felt it to be a sensory perception.
3152000	3180000	Again, sensory perception migrations and so basically I see huge value in taking this at least some epistemological thinking, which is again the past to address the challenges of the present, which is building them up into systems that can process data and produce meaningful outputs to actually build some sort of an emulator or plan for the future.
3180000	3194000	A sufficiently well-planned, sufficiently well-structured plan can be called an emulator because you can probably run it and play with it to emulate the conditions that might just happen.
3194000	3209000	So I'm basically starting from that hypothesis that what would it need to then build a system like that and turns out just that question has a lot of cross-cutting implications across the systems.
3209000	3212000	What is the difference?
3212000	3219000	What I'm hearing, what I'm hearing, not to cut you off, let's get you to do that.
3219000	3223000	Go on, finish it.
3223000	3228000	I mean, I'm just saying that maybe what you will be able to do is sum up that better.
3228000	3236000	Yes, so you're talking about the application aspect of this, which is the gradual next step anyway.
3236000	3246000	Once you have built up something that is solid, once you build up a tool that works, the next step is definitely application aspect of it, right?
3246000	3255000	The challenge there is I am very bad at that part or realizing when it's a good enough tool to be useful.
3255000	3258000	I am not interested in the application.
3258000	3263000	So to say when we say application, there is a certain application of philosophy.
3263000	3268000	When you are going into a debate, that is an application of philosophy, that is applied philosophy.
3268000	3271000	When you're writing a treatise, that is applied philosophy.
3271000	3280000	I'm saying there is a scope to build certain fundamental building blocks of software which exhibit these systems.
3280000	3284000	So just to map them out in just in the form of a framework.
3284000	3286000	Right, that part, got it.
3286000	3289000	Yeah, so when I say application, I'm talking of that.
3289000	3298000	I'm talking of it's like converting what somebody said as a proof to a series of mathematical equations if there is a logical flow.
3298000	3301000	So then what would be those components?
3301000	3304000	What would be like the building blocks of such a system?
3304000	3312000	And that keeps on taking me to a graph like nodes, components, actions, workflows kind of system.
3312000	3324000	And by now, so these were kind of niche, I would say in 2014, like flow based programming was like limited to airplane software design and all.
3324000	3333000	But now with the no code, low code thing, you see that everybody is implementing flows and kind of bringing back that part of things.
3333000	3339000	Which makes me think that we don't even need to build the application layer.
3339000	3356000	In the truest sense, we could be building that common API, that common library or the fundamental building blocks, which then, well, render using Unreal Engine, render using something like your user interfaces could be anything.
3357000	3366000	Build a game for all I care in which the learner is tested on Nya Epistemology.
3366000	3368000	Right.
3368000	3390000	The challenge that I am seeing here, the reason it seems like GPT-4 or maybe even GPT-5 or something like that would not readily be able to do this is because there's a fundamental issue of what their initial starting condition was.
3390000	3403000	And their initial starting condition was not to look at the world epistemically, the data that it has, but more.
3403000	3411000	I might be able, I might misinterpret this or say it wrong, but continue a conversation, essentially.
3411000	3417000	That's basically what it is trying to do by looking at all the data that has happened before.
3417000	3419000	Where the discussion goes.
3419000	3428000	Not really, it doesn't matter whether it's right or wrong or based on which framework can you decide or even approach it to be right or wrong.
3428000	3432000	And again, that Rajyuta Sharpa Brahm part, so I do see it.
3432000	3442000	What Google Bard has done is that it comes up with three different answers and lets you choose which one, which way of approaching it would you prefer.
3442000	3454000	Something similar can be done with various degrees of tunability where you can, for a model that actually is going that direction, where it actually has the understanding and interpretation.
3454000	3462000	If you want consequentialism as your preferred mechanism, then you go and interpret this this way.
3462000	3465000	But if you are more of a deontologist, you go that way.
3465000	3473000	And those two can both be the answers that you're looking for, depending on what your preferences are.
3473000	3476000	But it understands that, right?
3476000	3485000	There are some, so the models do, nowadays the models do understand those concepts a little bit, as in it will continue the discussion.
3485000	3488000	Claude does better than Chad GPT.
3488000	3492000	So Claude is probably the best one on that particular aspect.
3492000	3503000	But fundamentally, they are not built to, like for epistemic, they were built for just continuing conversation or discussion.
3503000	3506000	So that's where I see the challenge.
3506000	3508000	But it's not so much of a challenge.
3508000	3521000	It's just we have to wait a little while, maybe by the end of this year or early next year, by which time the entire, like the, we'll understand it enough.
3521000	3530000	But hey, now that we have done this, we have built the application layer of how to use these things or how to retrain them, how to how to fine tune them.
3530000	3534000	How to change the initial condition and what is required to do that.
3534000	3536000	Those parts will be better understood.
3536000	3542000	Once that is done, then we actually can build up a model that does exactly this.
3542000	3547000	In fact, that can become one of the co-hosts of this show.
3547000	3555000	And like basically fact check us or correct us or basically point our blind spots, saying that you forgot to do that.
3556000	3560000	Like you brought up the Naya Shastra into this, right?
3560000	3564000	That was helpful. That was yet another triangulation point.
3564000	3567000	It can do that much more readily.
3567000	3574000	Real time context that comes up, like whatever we're talking about, it comes, these are the things that already has discussed about these things.
3574000	3577000	And this is how you can connect it or there's a decoherence.
3577000	3580000	All those things can be approached that way.
3580000	3591000	I'm actually looking forward to that time that day, but I am not really sure exactly the process of how we can approach it right now.
3591000	3597000	It would take quite a lot of work to actually get that to reality.
3597000	3608000	Yeah, and I have been kind of hovering around this topic for a long while to the point that just what those fundamental data structures would be of such a system.
3609000	3612000	Because it looks like you can't leave everything to the AI.
3612000	3614000	You can't leave everything to the human.
3614000	3619000	And that is what these frameworks come in because they are a very well programmable set.
3619000	3631000	And just like being able to write that fundamental data structure in the way or not data structure, like the let's say the solution in a way that you have these nodes, you have
3632000	3637000	like you basically actions, functions, whichever way you put it there.
3637000	3639000	I have tried three, four different ways.
3639000	3653000	And in each of them, where the AI plugs in is as a very specific purpose, well trained computation on very narrow band aspects of things.
3654000	3664000	But again, this is connected to like my goal with this is, remember what I said that I want libraries to form as I continue living my life.
3664000	3668000	It's basically tying to that, right?
3668000	3677000	That retrievability is a very strong aspect of each of these.
3677000	3689000	So to continue to continue from that aspect, I am seeing a lot of positive movements on in that direction where the nebulas.
3689000	3691000	You remember I complained about that.
3691000	3704000	Hey, we have come to a point where I can write a node module and somebody somewhere in Serbia or Indonesia, people can just pull it and use it to the API that I have defined.
3704000	3708000	And it will be the entire ecosystem is very well formed.
3708000	3715000	But if I write a paper about something, you cannot readily utilize it in your math readily.
3715000	3721000	It still will have to be somebody who has to go through all those different people who are reviewing that.
3721000	3729000	Proving something had been nebulas and very much human dependent for a long part, a long time.
3730000	3735000	Now, some progress are being made to challenge that.
3735000	3738000	In fact, mathematicians are kind of getting frustrated about it.
3738000	3743000	What's what's the need for us in that case anymore?
3743000	3748000	So this is one of the I don't know whether this is going to be the winner in that sense.
3748000	3751000	But this approaches that and solves that problem.
3752000	3763000	How do you pitch a proof proof of something that connects from human to machine bidirectional rate?
3763000	3770000	So now systems as well as systems can prove things and present it to humans.
3770000	3774000	Humans can verify add or and or add addendum to that.
3774000	3777000	But all those things are possible.
3777000	3779000	This is huge in a sense.
3779000	3785000	If we have a deterministic system for proving knowledge.
3785000	3791000	And we can set the data point about, hey, these are the data points.
3791000	3801000	Now, those two things combined actually helps us get to the point that we're talking about, where there's a model that can do that.
3801000	3811000	Be assistive enough or basically just complete enough information, complete enough in that regard that we can go and ask some about something or introduce a new data point.
3811000	3821000	And it will have enough context to know which bucket to put it in, how to create the embeddings, where the vector location it falls on.
3821000	3824000	So I'm seeing a lot of potential there.
3824000	3833000	I wanted to discuss this, but like bring this one out since I discovered it, but didn't come out as an idea.
3833000	3836000	I couldn't remember it when I needed to.
3836000	3839000	This time I remembered it.
3839000	3840000	Look into that.
3840000	3843000	You might like it.
3843000	3846000	You're talking of the lean provers that you share.
3846000	3847000	Yeah, yeah.
3847000	3859000	The ecosystem around it or the same way what chat GPT made frustrated the school teachers, in a sense.
3859000	3868000	Similarly, this lean prover is making mathematicians frustrated in that particular narrow domain, fringe domain.
3868000	3873000	I just want you to just go through that and have that in your context.
3873000	3882000	When we're talking about these topics that hey, tools like this are either they already exist, or they would become relevant in upcoming time.
3882000	3886000	Think about Rust back in 2013.
3886000	3888000	Right, something like that.
3888000	3892000	This is the lean prover is like Rust back in 2013.
3892000	3895000	I just realized I had unmuted and then I went to speak.
3895000	3900000	I muted myself.
3900000	3908000	As it happens, I have tried implementing the basics in so many different languages.
3908000	3910000	I have a go version.
3910000	3912000	I have JS, vanilla JS.
3912000	3913000	I have sales JS.
3913000	3919000	I haven't tried Python because well.
3919000	3924000	But Rust is where these concepts just fit.
3924000	3926000	Even Haskell.
3926000	3930000	I have tried both Haskell and OCaml and it was like, okay, nice.
3930000	3933000	If I was a mathematician, I would have approved.
3933000	3944000	But with Rust implementing some of these, it feels like the language was built to handle these sort of complex low level systems.
3945000	3953000	And which makes like what the point I wanted to make is like Rust is the natural choice to implement any such things that we are discussing.
3953000	3956000	And then make use of the API, make use of Wasm.
3956000	3962000	You are opening up doors to pretty much every other reason for that.
3962000	3964000	Why did that end up happening?
3964000	3968000	I do feel like it's one of those critical inflection points, right?
3968000	3974000	That at a point when we are saying historically about the Rust project, I don't know.
3974000	3980000	I'm talking about why Rust ended up becoming this.
3980000	3987000	If you remember, it went through two sets of transformation, like massive transformations.
3987000	3992000	But where it landed, it seems very appropriate for this.
3992000	3993000	I mean, why?
3993000	3996000	The borrow checker frustrated people, of course.
3996000	4009000	But then the type system, the uncompromising focus on maintaining that type system, because it is the type system which makes it ergonomic to implement a lot of these.
4009000	4022000	The second was Rust deciding not to be just an unsociable nerd, but actually become sociable, get into that geek category.
4022000	4026000	And, you know, connect with other things.
4026000	4036000	So the API, the core was built from the foundation, like at least it's part of that, where it is possible to connect, look into Rust from other systems.
4036000	4040000	So connectivity from other, open to connections.
4040000	4048000	And then the incremental build that you were saying that it built upon the mistakes of the past while looking into the future.
4048000	4056000	But it learned the good things from the past, implemented for the present while looking at what future software can do.
4056000	4067000	I think I'll have to rephrase the thing that I was going to say with your information, because that makes a lot of sense.
4067000	4084000	What I was going to say is that it had the starting condition, the initial condition, what it tried to do, a kind of made sure that if it is successful to do that, it will end up in a state where it is ending up.
4084000	4098000	However, I realized there are other, let's say other languages, they tried to be purist in that sense, had very strong sense of like where it needs to go, etc.
4098000	4104000	But then they didn't get exactly the same way where Rust went.
4104000	4123000	And the part is, what you mentioned, being the sociable thing, like taking the feedback, be willing to change yourself well enough with time and with the requirement of people, even though it's not fun for you and it gets you down from your high horse.
4123000	4132000	It's worth enough to go through the transformation, go through the Laravel and PewPaw stages to get to that.
4132000	4142000	Otherwise, you get stuck in a self-loving, like echo chambers, like Haskell and many other languages like that.
4142000	4158000	They live that life. They're pure in a certain sense. And because they love their purism, that purism so damn much, they don't want to end up becoming what is popular by sacrificing some of the part that other people do not like about.
4158000	4168000	Where Rust actually did, like, OK, you don't like it that, like, it's not convenient enough. OK, let's make it easier for wider people, which helped.
4168000	4180000	Sometimes they even went back. Some concepts actually went back after making it way too like mushy mushy and then it's not landing well enough.
4181000	4197000	So that being willing to change with time and for wider spread basically is the fundamental aspect of what makes a species survive, basically survivalist approach to things.
4197000	4207000	That's what, along with the starting condition, because that is required. Without that, you again, you will lose your way. You need that.
4207000	4216000	But not being afraid to change with time, as long as you have your not star fixed. Those two things together is what got it there.
4216000	4235000	I'm pretty happy that one of the languages did, because usually what ends up happening, things that I put my bets on or things that I like, quote unquote, end up failing massively because of that extensive purist standpoint.
4235000	4249000	I'm really rather happy. I also came down from that extensive purist standpoint for myself and also saw that all the different projects or aspects of life that came down from that.
4249000	4257000	That transformation, that metamorphosis is what gives them the extra extended life that carries them to the next section, next phase.
4257000	4268000	No, no, no, Edmund, it's going in the same direction. Carry on, carry on.
4268000	4276000	I don't know whether to bring out yet another topic, but I have a couple of those things that I have been looking into.
4276000	4288000	So first of all, not first of all, in this particular topic that we are going into for that topic, sublist, for this sublist, first of all.
4288000	4303000	So I had a plan about because it fit. I have a plan about approaching three different topics and having three different names for the books called white matter, gray matter and dark matter.
4304000	4308000	So the white matter is basically the philosophy.
4308000	4320000	Gray matter is about the human condition, the psychological aspect of things, and the dark matter is about on physics, like the cosmology, et cetera, et cetera.
4320000	4325000	All those three things, concepts basically connect together. But that was the approach.
4325000	4331000	I'm not so sure because they're kind of like boiling down to the same thing, same part.
4331000	4351000	It's a little bit weird, but it seems like when you're trying to decide on the discuss on that white matter, the gray matter affects that your perception, your human condition affects the epistemic that you see and the interpretation of the reality also gets affected by that.
4351000	4358000	One aspect of that was the philosophy of metamorphosis.
4358000	4378000	Looking at the systems that are impure and impure the exact right way that it becomes advantageous to be impure in that matter.
4378000	4388000	Think about Voldemort as one example.
4388000	4403000	Think about the silicon as in doped semiconductors as one example, where the right amount of doping is what gives them the superpower.
4403000	4408000	Other than that, they are not super in any sense.
4408000	4419000	What is it about things that when we assign value to something, we kind of do that in a Boolean sense, we say something is good, something is bad.
4419000	4428000	That has been that entire moral and ethical schools of all different ways to think about it.
4428000	4434000	Aristotle did pose a kind of a middle ground, OK, too much, too little and just right.
4434000	4446000	I want to kind of expand on that just right part from the from the perspective of it does not live in a vacuum that just right.
4446000	4449000	Are you familiar with the concept that I'm talking about?
4450000	4454000	So just to just to for anybody listening to this.
4454000	4466000	So before Aristotle, like Plato and what's his name, Socrates, their philosophy was there's good, virtue and vice.
4466000	4470000	And they're kind of Boolean in a sense, good and bad.
4470000	4473000	Aristotle was like, no, here's the thing.
4473000	4476000	Too much of anything is bad.
4476000	4486000	If you are a person that is way too serious, that is not going to be registered as a good thing and would be beneficial for you.
4486000	4491000	If you're too much of a callous person, that also is not going to get registered as a good thing.
4491000	4499000	If you can bridge those two things together to come to a middle ground where you are serious enough but cheerful enough,
4499000	4504000	that is going to be give you the charm that people are looking for that is going to work in your favor.
4504000	4508000	So that's the that's the ground he was working with.
4508000	4520000	He kind of created nine of those sections and all those things, all different things that I don't think that set of like those nine items were comprehensive enough or anything.
4520000	4526000	But it establishes the point that you can see that in a spectrum.
4526000	4537000	My perspective is that you can still do that in a vacuum for any of the virtues, advices by themselves.
4537000	4549000	You have to look at it in which playground you are playing.
4549000	4555000	Carry on, carry on. You can get into this.
4555000	4565000	So the point I was trying to make is that you have to look at it in terms of where is this tool being applied.
4565000	4575000	And that's where that particular customization, which any of those attributes, any of the traits can be termed as good or bad.
4575000	4584000	But depending on the use cases, the utilitarian perspective, some of those things can be identified as advantages.
4584000	4589000	That's exactly what mutation is all about.
4589000	4597000	How mutation kind of promotes evolution and survival of the species.
4597000	4601000	That is the thing, the stochastic changes in some certain things that ends up.
4601000	4617000	So that's how evolution basically promotes, OK, go through multiple generations of things and whatever is supposed to stick around will stick around by just trial and error.
4617000	4622000	That's a very brute force way of doing something.
4622000	4630000	That is, evolution does not have a brain of its own.
4630000	4648000	But the way it ensures survival purely to its teleological own end, can you survive well enough to create another version of you with the good traits that you have and just loop that?
4648000	4658000	So how am I going to now come coming back to the talk about the entire part about the philosophy of halflings?
4658000	4662000	And then I'll go to the metamorphosis part, the halfling, the impurity.
4662000	4674000	So various different aspects of life in various different aspects of life, there are traits that people can use that gives them an advantage.
4674000	4678000	Or not only people like it transcends that.
4678000	4687000	But whenever you're trying to think of any of those traits in a vacuum, you can come to a like it's good or it's bad.
4687000	4695000	But the moment it gets infused with other things, other aspects of that, it becomes completely different.
4695000	4700000	It becomes either a necessity or a disadvantage in a sense.
4700000	4707000	Like a squirrel, you might not think why having a wing would be advantageous.
4707000	4726000	But if a squirrel gets the mutation of flappy like that handling the passive to support a passive flight from jump from tree to tree, how does that gives it evolutionary benefit to sustain its legacy?
4726000	4728000	That is stochastic.
4728000	4731000	It's a weird addition.
4731000	4733000	And those kind of weird additions are always there.
4733000	4740000	Usually we're not mindful about those things.
4740000	4742000	This does not live.
4742000	4745000	This entire concept does not live.
4745000	4750000	In a pure.
4750000	4754000	Interpretation of first virtual advice.
4754000	4758000	How do we frame that?
4758000	4760000	Because this becomes very utilitarian.
4760000	4766000	And that also might be a problem for some as in people who see things as a deontological perspective.
4766000	4771000	From that, they need to know whether something is good or bad.
4771000	4782000	How do we reconcile that aspect of things like sometimes there is no good or bad or there absolutely is we're just not looking at it right.
4782000	4784000	How do you think about this?
4784000	4794000	By the way, are you utilitarian or are you deontologist?
4794000	4798000	I believe in complexity.
4798000	4803000	And whoever gives me the complexity because I'm their slave.
4804000	4814000	Why I said that was that my gripe with most of these things is not about the.
4814000	4829000	It's not about if anything is good or bad or how people understand my gripe is the sort of reductionist approach of morality to constantly try to bring things down to.
4829000	4834000	Now, very polarized, very small set of values.
4834000	4838000	And what happens when multiple things interact, which is what you were saying.
4838000	4842000	I mean, I'm just adding to yours, not getting that.
4842000	4853000	The issue is that when some form of event interaction, some form of complexity comes up, that is when.
4853000	4859000	The smaller free thought framework, smaller, smaller moral frameworks break down.
4859000	4866000	Even if you progressed as much as saying that a good and bad are not two values, it's a spectrum.
4866000	4874000	You are still susceptible to the same thing because you are still susceptible to that one dimensional mapping of everything that is going on.
4874000	4889000	And. If anything, that generative is showing us is that to achieve higher and higher truth, better and better understanding and better and better predictions, we need to embrace more complexity.
4889000	4894000	We need to think in more dimensions, compute that many instances.
4894000	4900000	Now, what I'm trying to say is that this there is a certain.
4900000	4907000	There is a certain way of even building systems.
4907000	4926000	And I don't just mean software systems, a reductionist way of building systems, which in like, which wants to bring things down to this concepts of pure, impure, good, bad, impure being card, like the not pure existence of the not pure.
4926000	4930000	As often happens in that sense, the not pure happened to be the minority.
4930000	4939000	The pure happened to be the majority or the historical origins in which the pure happened to be the older, the non pure happened to be the newer.
4939000	4952000	So this line of inquiry, the slippery slope is it often leads to the kinds of bias where the system, the legality of the system is justified.
4952000	4962000	But the effect it has outside that system outside the purview of that system is often disastrous and disastrous to the point of no recovery.
4962000	4971000	Like there is a certain point of no return because you have simplified things so much you cannot trace back to what complex origins they were.
4971000	4979000	And that is when superstitions emerge or let's say xenophobia emerges and a bunch of these things can be traced back.
4979000	4988000	But then there is a certain value in retaining the complexity to a certain level.
4988000	4994000	So you are map reducing definitely because you want certain things to be computed.
4994000	5006000	But then the question is, what are those points of intervention in which the actor in this moralistic computation needs to step in and make certain micro judgments?
5006000	5013000	As opposed to be given a good or bad result. You can get a good or bad result if you want to.
5013000	5022000	And some of these concepts also underpin the reformation of justice systems that we see today around us.
5023000	5044000	The entire conversations around death penalties or around like mass incarceration that reform community work as a better option to mass incarceration, which like saves the state money and so on.
5044000	5051000	But if you look at the other perspective that what you are saying is that it's not pure and impure elements of the society.
5051000	5058000	I know I'm going towards society a bit, but just to draw that analogy that why diversity?
5058000	5066000	Why be inclusive? And again, connecting back to what did Rust do, which is where we kind of went into this from.
5066000	5078000	Is Rust embraced this resisting the reductionism, so to say, that it said that, OK, you cannot just say that these are this is the way to build software.
5078000	5084000	Everything else is irrelevant. What it did was set certain core guarantees.
5084000	5093000	One of them, one of those principles happened to be zero cost abstractions, which said that if I remove the runtime, if I reduce the runtime to near zero,
5093000	5105000	or if you're using just the same crust, you don't have a runtime, in which case you should be able to write your code in any form that you choose.
5105000	5108000	You want classes, you want excessive abstraction.
5108000	5116000	You can do that, but they are zero cost because end of the day, they are getting compiled to the similar underlying machine code.
5116000	5122000	Now, what that gives, if you look at it, it's very federal in nature.
5122000	5126000	It's saying that the core constitution remains the same.
5126000	5132000	You should try to stay as close to the constitution, but certain traditions are different for you.
5132000	5137000	You don't eat this. You don't drink that. You don't want this. You want these notable.
5137000	5148000	That's fine. You should still be able to run the same federal system without trying to impose on each other or take over the system.
5148000	5159000	So this is the sort of ingrained decentralized federal nature of also looking at community, of also looking at the systems.
5159000	5164000	The same thoughts build the systems, the same thoughts like the community first approach.
5164000	5180000	It's kind of like I described this to somebody a few weeks back that rust is basically at some point introverts, introverts in which ever sense, like socially awkward people eventually deciding that they'll do better work if they just for once work with each other.
5180000	5185000	They don't have to like each other. They don't have to party with each other.
5185000	5192000	They have to build RFs together. They have to vocally critique the work. They have to review the pull requests. They have to draw the roadmaps.
5192000	5195000	Wait, it's kind of like a wizard's convention.
5195000	5202000	So in that sense, rust is like United Nations done right.
5202000	5208000	It has a functioning product. It is not a body crippled by similar, very similar motives.
5208000	5216000	If you compare what is it that United Nations does not want to do, which is what makes its progress slow.
5216000	5229000	And as it turns out, if you were to make some drastic changes in United Nations to ensure certain actions towards climate change, they start looking like some of the things that the rust community has done.
5229000	5233000	Some point you have to draw a boundary and say no.
5233000	5241000	But at some points you also have to be accommodating, convince the existing people in the group that you have to let these people in.
5241000	5246000	You cannot be a roadblock. You cannot block their coming into the community.
5246000	5253000	But to those new people coming in, also sensitize them that look, this is the existing set of people.
5253000	5261000	Once you are in, you have to play by these rules and these are non-negotiable.
5261000	5266000	So, yeah, I mean, I was just trying to tie this together.
5267000	5271000	I see the point in like the connection between the two.
5271000	5284000	Yes. Yeah. So the morality part, what I feel is the question should not be one that of purity and impurity.
5284000	5290000	The question of purity only comes in the case of the conductivity.
5290000	5300000	If the purpose is verified that do we need a homogeneous society?
5300000	5302000	Do we need a homogeneous classroom?
5302000	5312000	Do we need a homogeneous colony, country or a homogeneous even software system?
5312000	5319000	In whichever way you think of it, it seems like if it is more result oriented, if it is more outcome oriented,
5319000	5323000	then the first thing to identify is the purpose valid.
5323000	5333000	So, for example, you say that we need only like certain type of people in the army for the army to function at its peak,
5333000	5337000	which then goes into gender segregation, racial segregation, caste segregation,
5337000	5340000	because upper caste people won't take orders from lower caste people.
5340000	5344000	So you have to break down caste, it seems, before you can have a functional army.
5344000	5350000	And then army is like, you know what, let's just hire upper class men or upper caste men.
5350000	5352000	That is one way to solve the problem.
5352000	5354000	The entire thing will operate very smoothly.
5354000	5364000	But unless you establish the purpose then and what I'm trying to do is bring in the complexity and saying that do not anchor on the end result.
5364000	5367000	Do not just evaluate the end result.
5367000	5378000	Evaluate the purpose, evaluate the process and compute the end result and have the heart, have the courage to accept that end result.
5378000	5390000	If you have put, if your process is well established, if your purpose is well reviewed and you are executing in a certain way,
5390000	5398000	be okay with the results because it's likely that you have not seen certain variables which might be impediments during your design.
5398000	5408000	This is called the agile way in software development, as it turns out, that be open to reacting to things, optimize process for people,
5408000	5411000	build processes for people, not the other way around.
5411000	5419000	And the reason humanity keeps on circling back on some of these core tenets is that it seems like if you ignore complexity,
5419000	5430000	you are doing the same kind of idiotic gesture that a hunter gatherer human just tries to be careful of the tiger
5430000	5437000	at the peril of ignoring the forest fire, which is I want to give tigers away.
5437000	5439000	I want to put fires all around me.
5439000	5440000	Tigers are bad.
5441000	5445000	So basically you don't want to go down that reductionism.
5445000	5456000	Now why, where this is the slippery slope is minds like your and mine can constantly self-check and stay on a certain blade's edge.
5456000	5463000	Even when conducting something which is just with two values or which is with homogeneous, there is that sense of alertness.
5463000	5468000	On an average, humans don't have that alertness, that self-correction is missing.
5468000	5475000	And which is why you see religious dogmatism pervade to the point because those are simpler frameworks to look at the world.
5475000	5477000	These people are not stupid.
5477000	5482000	They're not stupid in the sense that they are not capable of computation.
5482000	5490000	But you just can't compare a Pentium II processor, put it with a core i9, give them the same task.
5490000	5494000	I mean, not the right example.
5494000	5495000	Not the right example.
5495000	5497000	In a sense, I was trying to correct the analogies.
5497000	5499000	It's not about hardware, hardware.
5499000	5500000	Not about the hardware.
5500000	5503000	The software that is running is not does not understand.
5503000	5504000	Yeah.
5504000	5505000	Yeah.
5505000	5509000	I mean, in that sense, it's more like Windows kind of different.
5509000	5510000	It's a Linux version.
5510000	5512000	The exact same core i9.
5512000	5516000	If you apply the right software, it can work differently.
5516000	5522000	And what is the difference that Windows is trying to take a lot more decision for you?
5522000	5523000	Yeah.
5523000	5524000	What does religion?
5524000	5526000	What is the solace of religion?
5526000	5528000	Practicing religion.
5528000	5529000	It is computing.
5529000	5532000	So it is giving you a small set of model codes.
5532000	5533000	Precomputed.
5533000	5536000	Believe in it.
5536000	5538000	Delegating.
5538000	5540000	Limited customizability.
5540000	5541000	Yeah.
5541000	5543000	So what is religion doing for you?
5543000	5546000	I was trying to answer that question.
5546000	5549000	Would that be delegating responsibility in a sense?
5550000	5551000	It is.
5551000	5553000	Instead of trying to figure it out.
5553000	5555000	I'll do it myself.
5555000	5562000	And no, this is so that kind of goes into a discussion about.
5562000	5571000	Isn't there a saying about like know what you can control, know what you cannot control and know the differences, something like that.
5571000	5572000	It sounds something like that.
5572000	5574000	I'm pretty sure I'm messing it up in a sense.
5574000	5578000	So what it says that there are things that you cannot control.
5578000	5596000	Don't be too worried about it because there is also again overdoing that part and going into substance abuse and all the other kind of things where it kind of helps to assign that to a destiny or a God or something like that.
5596000	5598000	That's the part I cannot control.
5598000	5600000	Let let that be it.
5600000	5602000	Whatever that is.
5602000	5610000	Let's focus on the part that I can control and hope that my life turns out as something that I am OK with or happy with.
5610000	5615000	Or I can give myself the illusion of that's the best life that I can have.
5615000	5621000	That pretty much where it boils down to the entire concept of worship.
5621000	5630000	Why would you want to worship something or go back to like.
5630000	5637000	Basically sign your free will away in a sense to some extent.
5637000	5641000	If something happens because your destiny wanted it to be.
5641000	5647000	That means it's not that you that changed the destiny but destiny wanted your path to go that way.
5647000	5652000	So that is kind of signing off signing away your free will in a sense.
5652000	5653000	Why would you.
5653000	5658000	Again it doesn't matter where I stand on the free will part like the.
5658000	5661000	Keeping that aside I'm talking about in general sense.
5661000	5666000	So that's where the concept of this entire.
5666000	5670000	So that results into a broken self regulation.
5670000	5674000	If you are expecting somebody is doing the regulation.
5674000	5679000	That means you are not responsible or liable for the regulation.
5679000	5682000	And what happens when we don't use a particular muscle.
5682000	5684000	It atrophies right.
5684000	5692000	So that's the same thing when you are talking about the part about being able to work or like walk on the knife's edge.
5692000	5697000	And not being able to why that happens why people don't.
5697000	5706000	Like most in general don't want to or can't or fail to walk like walk on the knife's edge because they lose that muscle.
5706000	5717000	They lose that self regulation because they attribute the delegate that self regulation regulation part itself on somebody else.
5717000	5720000	And I'm not talking about only on religion.
5720000	5730000	It does come down to the regulation of the justice justice system etc.
5730000	5734000	It also does come down to that is the comes down to the governments as well.
5734000	5744000	All the system where you need to look up to somebody like a big brother or a father figure in order to get something done anywhere that is.
5744000	5749000	That means you are weakening yourself.
5749000	5761000	You are not just a small political commentary at this point is this is the part I feel like resonates the most with Ambedkar warning people about hero worship in Indian politics.
5762000	5773000	And he was kind of talking from this delegation perspective as well that we are prone to doing that because it is easier because it is convenient.
5774000	5792000	But yeah end of commentary the curious part though in all of this is that you can in fact live your life in binaries but just wanted to tie this up to one of the maxims of life for me.
5792000	5804000	I think I briefly touched it on last days be wary of binaries and I mean be excessively skeptical of monogamists.
5804000	5813000	And in either sense the reason for that wariness is that it's OK to walk on that knife's edge.
5813000	5822000	And again each of these systems that we are talking of what are they trying to do the role they play in a human's life.
5822000	5836000	They are sort of a competitor to religious beliefs you will find at every step whether they mock or ridicule or this they claim to be delivering an alternate lifestyle to what everyday religious practice is granting.
5836000	5846000	And that is in sort of the complexity of things but how it grants is it says that you would eventually go back to doing the same kind of things.
5846000	5857000	You would eventually understand what is good or bad what is the self what is the other you would end up with this knowledge of binary but by then you would have learned how to compute the binary.
5858000	5872000	And walking on that knife's edge is then that balancing act that you are doing constantly evaluating checking yourself that are you at any point transgressing these boundaries which should then call to question your final decision.
5872000	5899000	Which means it's saying that with enough practice in a certain form humans can be better model like more moralistic creatures be able to compute good and bad quicker because it also can warns you about the non-computational complexity owning problem that you suddenly expose yourself to a lot of complexity and you hit that numbness the indecision.
5899000	5915000	So for these traditions the goal is not to stay in that indecision but to be decision makers very fast decision makers very intuitive decision makers very decision making is backed by these things.
5915000	5938000	So you're not offloading that computation unless you're offloading that computation to certain systems which form under this and that is where their proof of knowledge their way to motion all come in basically they're saying that you can if you want to be the dharmic some say that some say that you be the ideal citizen.
5938000	5952000	Most of these are chasing ideals in some way or the other and that ideal is that blue line you know that that is where you want to be they're first pointing that out so they begin with a hypothesis.
5952000	5956000	No that's not a hypothesis that's the set point that is.
5956000	5979000	I'm saying they begin with the hypothesis that we want to be there let's first prove our intention it's at the starting point it's like saying first you do you think you want to go first figure that out before you start on your journey you don't want to be lost so you start on your journey look up the map do your research then start walking.
5980000	5992000	So then you start approaching that curve so basically in this foundational work a lot happens in that part before takeoff.
5992000	6010000	And that is the initial state basically the valid verification and validity of that initial state is just as important for them to then say that you will go the right way so they're basically putting that computation there charting your path then letting you go.
6010000	6023000	It's like if you then follow the trajectory it's like Chochandra and three right with minor remote commands you should be able to land in the right place but the computation is done before launch.
6023000	6047000	My interpretation of that is it starts the way it starts it starts holding hands of a very limited set of entities that wants to head that way over time more associations come in and gives it the momentum it needs which is why it gets closer.
6047000	6067000	Now the only challenge is again I don't want to like harp on that particular thing for far too long the proportionality part of things it basically whenever it reaches close enough it basically loses the interest we got almost there so I'm not interested about it anymore.
6067000	6082000	In that sense a lot of people have become comfortable at the 80% like reaching 80% success and be fine with that that's when you need to find the people who are like no this is not ideal we need to pull it out and that's where the integral comes in.
6082000	6098000	So again not to dwell on that but I think that's the way it's not about pre-planning the whole thing before the journey starts that's not even though I prefer it to be that way the planners self would want to be that way usually.
6098000	6104000	You are like identifying the stages like the root so to say.
6104000	6121000	Yeah I'm saying that somebody just starts going that way gradually more people join in and figure that part out the plan on the way usually that's how pretty much everything like the all the revolution that's how it happens.
6121000	6139000	The plan is not set in stone and it's not that if you if you keep it that way and don't adapt with changes you're actually going to have much more much of a success you're actually going to fail because the reality is much more messy and chaotic than you can plan out to be like complete details right.
6139000	6156000	So the part the part of the other thing is that it's not completely planned out from beforehand somebody some entity some particular person that wants to leave a mark on the reality starts heading on one way and either they get the momentum to go that direction or they don't.
6156000	6165000	For any kind of set point approach you see there's thousands of set point approaches that we don't see because they fail right.
6165000	6180000	So that was the other point that I was trying to make from what you are saying I was I don't know whether it goes as a correction or an addendum but that's how I'm seeing it the way it starts off the journey starts essentially.
6181000	6196000	So what I meant by charting the route is basically identifying intervention points possible intervention points having certain event based thing you know like I'm saying I'm just telling you how the systems.
6197000	6220000	How I'm saying how this knowledge systems work so when they are how do they do research so basically when you go into the AI and I'm talking about okay so my way when you do that is I was saying that when you do that how the approach is broken down it's basically the question of how do you acquire knowledge.
6220000	6244000	And you are talking about subset of people who are into this yeah I'm talking subset of people who are understanding was my thinking the mass yeah so my question and this is my lifelong question is that how can I that is what you're saying that how can I take what these people know to the masses that what would that look like that was one of those hypothetical things that I had.
6244000	6256000	Good but that was the question I wanted to pose it now I just want to wrap this up this part of the discussion and I think the final thing to mention here is he.
6256000	6262000	The important part then in the human machine interface conversation.
6263000	6268000	Becomes identifying like having that ability to.
6268000	6291000	Becomes identifying like having that ability to synthesize from a hypothesis that is put to action by actors of certain sort like the thesis and the antithesis being put to work contrasted with the hypothesis.
6291000	6303000	But the part that I agree with you is that the obvious expansion to hegelian dialectic is the ad that the synthesis is the goal.
6303000	6306000	Formation of it is not.
6306000	6310000	And you want to introduce that hypothetical state.
6310000	6320000	At which point you have a I don't know if it is more is it like but at that point you have more of a new hegel hybrid.
6320000	6322000	In the system.
6322000	6328000	And what I probably harping on a bit too much not to fan.
6328000	6345000	Because I know that I'm taking one example philosophy actually does not de stigmatize like that that hypothesis yeah so that is what I mean that Nia is most most eastern traditions do not stigmatize hypothesis in fact they encourage this is what I was trying to say yes.
6345000	6350000	These traditions encourage open ended skepticism.
6350000	6361000	And they say that open ended if you do a close ended inquiry close ended inquiry being tracing back from God.
6361000	6366000	Yeah, you have already gone to the farthest extreme and you are coming down.
6366000	6371000	That is where things are prone to reduction reductionist approaches.
6371000	6379000	But if you go inward out, which is what they mean by saying that no Brahma by knowing yourself.
6379000	6391000	So what does it mean by to know yourself is your first knowing your surroundings and you're working out from that and these two create very interesting differences.
6391000	6406000	The inside out tradition is a farmer synthetic tradition far more inclusive they result in frameworks which want people to come in study observe be together build.
6406000	6410000	You know systems to work with them better.
6410000	6418000	Whereas the other one leads down to more our majority is in danger kind of attitude.
6418000	6426000	Because it has already known the extreme and everything then has to fit that narrative or it will be forced fit.
6426000	6432000	At the cost of boxing out removing the impurities to make it pure.
6432000	6448000	And this very interestingly again a lot of American queer politics uses language which is very reductionist in that sense and you end up with labels upon labels taxonomy done reversed.
6448000	6453000	You are constantly breaking down one segment into 10 others.
6453000	6455000	But first you must have that one segment.
6455000	6462000	It's not like when you've identified there are 10 subsections within this one section you now say that okay this was a wrong categorization.
6462000	6464000	This was premature categorization.
6464000	6473000	No, it has to be a like directed acyclic graph of some sort.
6473000	6478000	I think I see the pattern in this and the reason for that.
6478000	6481000	Why people go that way.
6481000	6485000	So I sent you that Joichi Ito article.
6485000	6488000	I have it on my reading list.
6488000	6491000	I have I have certain opinions.
6491000	6497000	I want to know your take on that the problem statement you might not agree with the solution.
6497000	6504000	But it's the problem statement which you might find very dear to might I don't know.
6505000	6510000	The second link I sent is somebody else's critique of that work.
6510000	6515000	Do not read that till you feel like you have a good enough idea.
6515000	6516000	Got it.
6516000	6520000	I mean if you don't there is nothing you won't understand because it's primarily HCI.
6520000	6522000	It's primarily UX.
6522000	6523000	Okay.
6523000	6529000	The last point that you're trying to why reductionism pops out.
6529000	6532000	Why it ends up going that direction.
6532000	6536000	This is part of a bigger discussion yet again yet another topic.
6536000	6540000	And I know that for a past few sessions this will keep on happening.
6540000	6542000	So basically I think it will continue.
6542000	6543000	Yeah.
6543000	6548000	But the origin of religion itself you see there's a pattern to it.
6548000	6559000	It starts from the void and the highly philosophical the spiritual interpretation of energy something from nothing etc etc.
6559000	6565000	It quickly goes down into fundamental forces of nature as the gods.
6565000	6574000	And then it pops out as there are one one thing that matters more than all the other ones.
6574000	6583000	And after saying the general principle let's put that into perspective of Hinduism where initially you start with void.
6583000	6589000	There are three different gods that basically pops out over time.
6589000	6596000	It's not even like solidified in a once and like if you go through the purans and so you will find multiple different interpretation of that.
6596000	6603000	But eventually you get that OK these are the more philosophical standpoint of a fringe.
6603000	6609000	People at the end they have nothing else to do but think more deeply.
6609000	6612000	I mean specifically Vishnu Purana.
6612000	6626000	And before Vishnu Purana is where it's kind of transitioning like hey we need to convey this message to a little bit broader audience like the kings and the people in power.
6626000	6630000	So basically it's going out of the hands of scholars.
6630000	6637000	Scholars were fine with the very spiritual interpretation of it like the void and so the duality etc.
6637000	6641000	But now you need to simplify this for people who run countries.
6641000	6643000	The nations essentially.
6643000	6649000	So now you're trying to convey that message to the emperors.
6649000	6650000	How do you do that?
6650000	6658000	Now your story will revolve around creating the gods that are emperors and or their sidelines.
6658000	6663000	So now Zeus from Zeus like Norse mythology all those things even Hindu mythology like Indra and all this.
6663000	6676000	Now the story revolves around the fundamental forces of nature like Vayu and the sun basically the air the earth the power of war like war gods etc.
6676000	6683000	All those things basically come into the picture and that's the interpretation because that's the demography you are trying to reach out to.
6684000	6690000	And then the third level what happens is that is the mass is still out in the void.
6690000	6696000	They're basically the life is misery and there's no end to it.
6696000	6698000	You are living in that situation.
6698000	6704000	Somebody comes out says that hey look all those interpretations.
6704000	6711000	You are not in a position to understand this because you have been left in the gutter in your entire life.
6711000	6716000	Without the resources to actually reconcile with those concepts that they're talking about.
6716000	6724000	You don't have the tools or utility and you are in the part where you are at.
6724000	6728000	You are at a position if what position I'm not finding the right word for it.
6728000	6736000	Like you are your life has come to a point where you cannot go back and pay those debts and pick up the books and learn everything and then get to their same level.
6736000	6738000	It's not possible for you.
6738000	6743000	You need a simplified interpretation of this for you.
6743000	6758000	Those what do you call that thing like the Monashat Mongol and the story of the small gods story of the one God essentially like only focus on this particular guy.
6758000	6762000	And he basically he or she will basically take away all your pains.
6762000	6767000	That also goes down to all the extra bad as in the monotheism concepts as well.
6767000	6775000	Is that forget about the complexity and nuances of all the whole other things the way they have tried to interpret it for you.
6775000	6779000	Just this 10 commandments and this there's only one God.
6779000	6780000	That's all you need to know.
6780000	6788000	Life is easy delegate that decision making and self correction and regulation which you were not equipped with to begin with.
6788000	6791000	Now this your life is now much easier.
6791000	6792000	Go ahead.
6792000	6799000	Now all those people for all those people life is actually much easier because it takes away the pain takes away the confusion.
6799000	6807000	If you are having a misery because God intended that maybe you have done failed at one of those 10 commandments.
6807000	6810000	That's why you're having misery.
6810000	6818000	Anyways and for everything else all the carrots and sticks aside there's the ultimate one carrot and a stick heaven or hell.
6818000	6828000	So basically even if you feel like you you are going through the life not being punished for bad work or not being rewarded for your good ones.
6828000	6831000	You still keep on doing it because at the end of it there's a.
6831000	6843000	So all those things basically comes down to that reduction is the one one God one dimensional belief or worshipping tendency goes comes down from.
6843000	6855000	That entire part of the how do I I if I don't want to take responsibility for all that thing understanding all that thing or regulating myself.
6855000	6863000	How do I delegate that whole thing to a one particular God that I believe in and then it goes down that way.
6863000	6866000	So I'm not saying that it is only about religion.
6866000	6871000	It expands in multiple different dimensions including the ones that you have mentioned.
6871000	6887000	I also understand the paradox or not paradox the irony of me trying to reduce down the whole complexity and nuance of religion like the entire theological institution down to like OK.
6887000	6889000	Hey there's only three sections.
6889000	6890000	That's that's pretty much it.
6890000	6900000	I do understand that but sometimes you need to get a picture of a place to read as a memory and you cannot have the entire 3D model of the place that is not practical.
6900000	6902000	So that's the only reason I'm doing this.
6902000	6905000	But I think I guess that's how it ends up happening.
6905000	6914000	For some people just living with that like getting the really pain relief is not sufficient.
6914000	6928000	They will keep on running around trying to find more data point more and more at the cost of pain to look at more complexity to assimilate more complexity and find out a better model.
6928000	6935000	And they will take over the responsibility of regulation on themselves and some else would not want to do that.
6935000	6940000	They just want to have a happier and less painful life and they would want to delegate that.
6940000	6944000	OK, I'm done on that particular aspect that particular topic.
6944000	6953000	You sound that a better assimilate the complexity and find a better model.
6953000	6961000	Is the fundamental principle to build upon to in order to resist reduction.
6961000	6975000	And you're right that it takes a certain amount of madness to throw yourself constantly into the face of complexity because it is painful to the point of being physically painful depending on what you are doing.
6975000	6978000	But like the more complexity you embrace.
6978000	6983000	The key is to not stay in indecision.
6983000	6986000	There will be periods of indecision.
6986000	6990000	The key is to know how to break out of indecision.
6990000	6993000	And that is the assimilation aspect of things.
6993000	7006000	The only way you break out of indecision in the face of complexity is if you can assimilate the complexity into as a patch on your existing model and improve that at which point you have reduced.
7006000	7018000	So like I said, it is resisting in many sense the idea is to resist reducing but not stop doing it because MapReduce as a function is vitally important.
7018000	7039000	Which again, remember what we said in first episode that what is important is to store this MapReduce values, but also the computational like some sort of a theorem, be it a theorem or be it like an version control snapshot in some way to prove.
7039000	7043000	Those are the edges. If you see the node and edge aspects.
7043000	7052000	The reductions are the next set of nodes, but the process through it like if the function that it happens through it are the edges that connects them from.
7052000	7054000	You take this data point.
7054000	7057000	This is the function that you apply and you come up, come up over there.
7057000	7059000	If you apply a different function, you go somewhere else.
7059000	7069000	But knowing the intersection and interaction between them is where you cannot say that this one function is the rule them all and others don't matter.
7069000	7077000	That's one way. That's basically where the criticism I was making right now is that that's where people tend to go because that's easier.
7077000	7084000	So now from an HCI perspective as in human computer interface, the UX considerations, not just UX.
7084000	7089000	In fact, let's just call it interaction perspective, right?
7089000	7099000	The producer or the controller of the system goes from higher complexity to lower complexity.
7099000	7109000	The consumer of the system, the viewer, the accessor, the learner goes from lower complexity to higher complexity, traversing the same paths.
7109000	7115000	Are we going into that entropy discussion again? The designer entropy comes in every single time.
7115000	7117000	Entropy exists everywhere.
7117000	7120000	But what I said is no, no, I am not.
7120000	7122000	I'm just arriving at it.
7123000	7128000	In fact, I have I'm just starting back parts I have taken already, but it fits.
7128000	7142000	So basically the HCI considerations that you need to do is that your system needs to take in all the complexity, be constantly map reducing to give you the simplest set of values that can be portrayed on an interface.
7142000	7146000	So when you look at it, you look at it as the world that appears.
7146000	7160000	It appears as a world and apparently benign, devoid of details till you start looking into things and there are infinite layers upon layers of details that you could go in.
7160000	7174000	And this as a interface design principle, ever since I realized this has built possibly the best possible APIs, best possible practices that I could ever dream of.
7174000	7185000	Because connecting this back to API first, the idea behind API first design is not that you first build the API, then you think of what happens.
7185000	7202000	Now, it's about you identify all the possible variations in the system that can come in, identify the interaction points, the map reducible points, understand what to do with the end result and how to map this.
7202000	7204000	How do you hide this complexity?
7204000	7211000	Like it's like showing the map reduce result first, then showing the computation, then showing the input values.
7212000	7214000	What's wrong with that?
7214000	7216000	No, I'm saying not wrong with that.
7216000	7219000	This turns out to be an excellent API design strategy.
7219000	7227000	Yeah, I think so because think about it also from like, I hope you don't have other things to add there immediately.
7227000	7229000	I was just reflecting on that.
7229000	7240000	If we are talking about a new child, like in a sense like a new human trying to make sense of the world, how does that person start?
7240000	7242000	They have to start from a present.
7242000	7249000	And whenever they're curious, they can go back and look at how it came to be that tracing back your point.
7249000	7252000	The point and I also agree is that there needs to be the trace back point.
7252000	7254000	Like how do we get there?
7254000	7261000	The entire nodes and edges should be there, retained in a sense that anybody who wants to, who's curious enough, can go and check that back.
7261000	7268000	Most people wouldn't want all the paths, wouldn't check all the paths or wouldn't find the energy to do that.
7268000	7280000	Which is not like the point is you cannot force people to know you have to go read this particular like 5000 old year old book first.
7280000	7286000	Then only you get to come to like eventually understanding like the present.
7286000	7292000	You cannot, which is how I was taught philosophy that that is the chronological view.
7292000	7294000	Yeah, that it just doesn't fit.
7294000	7295000	It doesn't fit.
7295000	7296000	It is.
7296000	7297000	It is.
7297000	7300000	It doesn't fit even at a small scale.
7300000	7302000	At a very small scale.
7302000	7304000	Because the realities are so different.
7304000	7305000	Yeah.
7305000	7306000	The perspective is different.
7306000	7310000	And how do you expand on the perspective?
7310000	7319000	Take any of the quirks of our all those mega novels.
7319000	7320000	What do you call those things?
7320000	7323000	The Ramayan Mahabharata or like the epics, right?
7324000	7327000	So any take any of the quirks, right?
7327000	7329000	Why this is happening?
7329000	7337000	Why Vishwa can steal two women and get them married to his brother or whatever that is.
7337000	7344000	The point is, it seems like from our value of the present, it seems weird.
7344000	7349000	Now, if you ask the question, then you get the answer like further down the line.
7350000	7356000	Given that socio-economic situation, these are the things that were considered heroic or good enough.
7356000	7358000	Like it's not considered.
7358000	7360000	And then your understanding expands.
7360000	7368000	But what if you are forced to understand from that word first, as in from back to now,
7368000	7372000	your understanding of current would be super messed up.
7372000	7378000	Because at the highest level, you have a limited set of memory.
7378000	7381000	Memory is still as in memory in the sense of the compute element.
7381000	7383000	I'm not talking about the raw memory.
7383000	7387000	I'm talking about the amount of new neurons that you are working with.
7387000	7388000	That's limited.
7388000	7395000	Now, you can have somewhat functional model of the world view, the womb belt,
7395000	7400000	and then keep enriching it with more details as you find something interesting.
7400000	7406000	But if you start from the beginning, you already have a weird sense that weird model that doesn't fit now.
7406000	7412000	And then you're trying to retrofit it to a current model, which is screwed up.
7412000	7415000	I've seen this so many times and it frustrates me all the time.
7415000	7421000	And the challenge is to have this conversation with any of the systems,
7421000	7426000	I have to come from so far back and have the ground level discussion of so many things
7426000	7428000	that it doesn't make sense to have that discussion at all.
7428000	7431000	It's just like, okay, table flip, I'm out.
7431000	7434000	Basically, that's what ends up happening.
7434000	7437000	The table flip does not happen.
7437000	7439000	It happens inside my head.
7439000	7447000	Yeah, it just doesn't happen because it's that much more difficult to recreate the table in its current position.
7447000	7451000	Imagine if you could just reset.
7451000	7460000	But I just realized, I keep on saying that game design has a lot to teach the rest of application designers in software design.
7461000	7465000	And if you look at it, the good games embrace this philosophy that I just said,
7465000	7471000	that the designers design from a higher complexity to lower complexity.
7471000	7475000	The player starts from lower complexity towards higher complexity.
7475000	7480000	The games that do this the best to don't have a help panel.
7480000	7488000	The gameplay itself teaches you how to play.
7488000	7490000	The one immediate, two immediate, three immediate.
7490000	7493000	Okay, I can give multiple examples.
7493000	7498000	Portal, the starting of Portal or Half-Life.
7498000	7502000	Well, not Half-Life in general because Half-Life kind of started off from a certain...
7502000	7504000	All the Valve games.
7504000	7505000	All the Valve games.
7505000	7508000	So basically everything built on the Valve platform.
7508000	7516000	But Portal specifically, Portal 1 specifically in the way it teaches somebody absolutely not used to computer games,
7516000	7519000	not used to these controls to move.
7519000	7524000	And part of the story, and this is where the design from higher complexity to lower complexity,
7524000	7529000	part of the story is in the beginning telling you, it's okay, you're not able to get the controls right.
7529000	7532000	You remember that you're disoriented.
7532000	7534000	You just woke up from this cryo sleep.
7534000	7542000	And the validation it gives to the learner, I am not supposed to get it right immediately.
7543000	7550000	These things, unless the designers thought of the complexity that somebody might not even know the controls.
7550000	7556000	Have you played Stanley's Parable?
7556000	7557000	No.
7557000	7559000	Oh my God, you're missing out.
7559000	7562000	Go play that immediately after this.
7562000	7563000	Right.
7563000	7566000	Or maybe first read up on that.
7566000	7568000	That would give you a better mental.
7568000	7571000	Otherwise, it's going to feel a little bit frustrating at first.
7571000	7574000	But read up a little bit and then start with it.
7574000	7577000	You are touching on that point.
7577000	7584000	I just want to have that levels, the organic level of like, where does it land?
7584000	7590000	How Valve developers work and how much self aware their games are.
7590000	7594000	Stanley's Parable is an ode to that.
7594000	7600000	Like the game is made to be a self aware game.
7600000	7602000	I don't think you need to read anymore.
7602000	7605000	Just just go ahead and install and play.
7605000	7610000	So I think you're missing out if you don't play that game.
7610000	7611000	You will.
7611000	7613000	What you're saying is correct.
7613000	7614000	It's right.
7614000	7619000	You're just missing out on so much fun that I think you should enjoy this.
7619000	7621000	Yeah, I agree.
7622000	7628000	Basically, I'm trying to apply some of these into software design and ask these questions.
7628000	7633000	One of the reason of me trying to get out of the standard corporate ecosystem was I wanted to.
7633000	7635000	Now, it's time.
7635000	7641000	Like I have spent enough time doing application building in general terms.
7641000	7643000	I'm still doing that for money.
7643000	7650000	But the point is that I see software from this perspective that there are so many other challenges
7650000	7653000	for which certain solutions exist.
7653000	7656000	It's not like I was the first one to invent this.
7656000	7659000	It's just my observation that I am presenting here.
7659000	7664000	What that observation says is there is enough scope to bring some of these concepts,
7664000	7672000	apply them to certain other domains of human computer interaction or machine to machine interaction.
7672000	7683000	Interaction design fundamentally escaping the confines of a screen, escaping the confines of just a small software
7683000	7689000	being thought of as these interaction points in the world around in a broader context.
7689000	7691000	What does that mean?
7691000	7699000	And then what would it mean to even add with the current day technology, the immediate step, let's say,
7699000	7702000	because I think there is a scope to build up to this.
7702000	7715000	What is it that we can do today that in 10 years time have the last effect on making some of these ways of thinking more mainstream, more mainstream?
7715000	7721000	I am not saying I want 100 percent saturation, but I want to the level of saturation that let's say rust.
7721000	7723000	In fact, that's the point.
7723000	7726000	Let's not set a popularity as a matrix.
7726000	7727000	I don't.
7727000	7728000	I don't.
7728000	7738000	So I am like enough validation across a critical threshold of survival, beyond which it's propelled by community effort.
7738000	7748000	To the point I want to see these discussions manifest themselves to a point where they become the building block for the next generation to build on.
7748000	7749000	That's my goal.
7749000	7754000	Yep. OK.
7754000	7758000	I don't know how much time you have, but let's say that we have 15 more minutes.
7758000	7761000	I'm trying to find something, a chain of thought in five minutes.
7761000	7763000	I'll not give enough explanation.
7763000	7764000	Carry on, carry on.
7764000	7769000	But I have time to think over the course of the week.
7769000	7771000	This is how I'm thinking about this.
7771000	7780000	I think there's merit to bring this entire discussion, all those things as a platform, which we started with talking about.
7780000	7785000	But let's start it, the start of brink of new year.
7785000	7797000	And until then, we can have our practice runs of jotting down or basically get our ships in order, essentially.
7797000	7800000	So tell me, what does such a platform look like?
7800000	7802000	It doesn't have to be too much critical.
7802000	7804000	Basically, I already have something that is going.
7804000	7814000	I can reuse the anthropic inertia is one of the platforms that strikes me as the most like non.
7814000	7816000	I mean, to what end?
7816000	7818000	I'll come, I'll come to that.
7818000	7820000	To what end?
7820000	7822000	What is the end result of that is?
7822000	7826000	No, what are the end products?
7826000	7828000	That's what I'm coming to.
7828000	7835000	I'm talking about the brand first, because then I'll come to the product, like aspects of the physics of it.
7835000	7840000	So void was more of a like it was mischievous.
7840000	7843000	It was not welcoming enough.
7843000	7854000	But that's why I have multiple aspects of the anthropic inertia is the one that is actually it is a reflective platform supposed to be.
7854000	7859000	Yet it is not unwelcoming.
7859000	7866000	I have posted some things there, but I don't get enough time to do more.
7866000	7874000	Anthropic inertia has a YouTube channel, which I messed up a little bit with contents that I don't want to post anymore.
7874000	7876000	So very linear content.
7876000	7878000	It doesn't have the longevity, essentially.
7878000	7886000	But it also has a Spotify as in the podcast aspect of it, a sub stack and Spotify and Google Podcast and all.
7886000	7889000	So basically it has a podcast and it has a blog post.
7889000	7898000	What I usually do with the thoughts, like things that I've done so far is that I come with this come up with a script point that I want to make.
7898000	7902000	Then I write up about it, publish that on a sub stack.
7902000	7913000	I use my voice model to read it out loud and use that as the podcast for this podcast platforms.
7913000	7916000	I haven't started using the videos yet.
7916000	7923000	So if those audio we take the audio and generate video out of it and post it on YouTube, that can also be possible.
7923000	7937000	Point is that not the video point is the sub stack and the Spotify basically podcast subscriber model where people can tag along.
7937000	7941000	They basically press a button to let you know that they are with you.
7941000	7944000	They're listening.
7944000	7954000	So if there's what are what to what end, that's the end where people can give you signal that they are listening.
7954000	7968000	And then have a community of that where the discussions that we are having are having a second or third order harmonics resonant frequencies at that at multiple different levels.
7968000	7973000	Once we start establishing that, I'm again brand name.
7973000	7981000	Forget about that. I'm talking about the anthropic inertia is a perfect 20 to 23 company name or organization.
7981000	7987000	It is a good brand exact extent, which is why I come into the realization.
7987000	7990000	You even went with the acronyms mapping to AI.
7990000	7992000	Yeah, you see that, right?
7992000	7999000	It's not that unobvious like I know that you would say, but yeah, so those things are basically prebaked.
7999000	8002000	I see that it has a massive potential.
8002000	8004000	Let's do it right this time.
8004000	8005000	The right is in the sense.
8005000	8010000	Let's not be too hasty about it or look for fast gratification.
8010000	8012000	I know that it's going to take some time.
8012000	8021000	And given my calibration, like understanding of what happened in the past, it takes about two years for things to catch up to our expectations.
8021000	8032000	So maybe we would be we would have enough time to prepare ourselves to get to the point where enough people are listening.
8032000	8040000	So we need to be on topic.
8040000	8041000	Which is which is fine.
8041000	8043000	Something else struck me.
8043000	8045000	And of course, I'm the one that jumps the gun.
8045000	8047000	Exactly five minutes.
8047000	8049000	I'm getting a lot of latency from your hands.
8049000	8054000	Sorry, you have been eight bit there for like an hour.
8054000	8056000	OK, sorry.
8056000	8058000	But the video is video is much better.
8058000	8063000	You can see it on the end of 40.
8063000	8065000	I know the recording you're recording on your screen.
8065000	8067000	Yeah.
8067000	8068000	Yeah.
8068000	8069000	So that's that's fine.
8069000	8070000	So I watch the videos.
8070000	8075000	I've been doing that for the last two weeks.
8075000	8088000	See, I see the entire thing that you said, the application, the applicability of converting this into carving out an application from this.
8088000	8092000	If it is again, just to see scratch our own itch.
8092000	8095000	I kind of see.
8095000	8097000	And this has been going on for a while.
8097000	8109000	There is a sort of merger of Kong's future version, let's say, which is up speak as the knowledge management system to a lot of people have been talking.
8109000	8121000	It probably came out the closest in your analysis just now that there is a gap for this creators platform.
8121000	8129000	Where knowledge creation or content creation has too much emphasis on quick creation, linear flow and so on.
8129000	8136000	How can we bring in complexity capturing thought processes to broadcast to audience engagement?
8136000	8140000	I'm kind of combining up speak and X flex in my head at this point.
8140000	8150000	I am no longer seeing those things as separate units, but basically a plumbing layer that again connects these things.
8150000	8159000	And if we build outside in, which is we start with the videos, we learn the audience engagement and build from there.
8159000	8164000	This will come up to with the knowledge management and these principles in place.
8164000	8170000	I see the following possible hypothetically.
8170000	8175000	There are discussions from the discussions just like this, whether we stream or not.
8175000	8181000	I can see a complete cycle, basically a very forward looking.
8181000	8183000	What's that called? Progressive loop.
8183000	8189000	What is the loop that adds value? Positive feedback loop.
8189000	8195000	So I'm seeing a positive feedback loop possible that start with this broadcast.
8195000	8197000	You get incrementally better. You narrow down your topics.
8197000	8208000	But these things being taken, the contents grouped into say a wiki, which go on to inform certain other discussions that others can participate.
8208000	8223000	Parallel forks of this conversation with parallel things other people doing, which can be merged, the synthesis of the idea where each contribution can be traced back to its origin story.
8223000	8230000	That basically community as part of your subscription.
8230000	8244000	So how do we bring you remember that was a problem statement to solve with Kong that how do you bring people who are listeners onto the platform without disturbing the flow is still a very interesting problem to solve here.
8244000	8252000	But I am now saying instead of that just being a real time problem, I want to make it a semantic problem.
8252000	8258000	I want to make it a very well deontological problem.
8258000	8261000	Yeah, you are deontological.
8261000	8266000	No, no, no.
8266000	8274000	I'm just saying that when I said deontological, I paused because there is an option to make it ontological, deontological, whichever direction you want to go.
8274000	8276000	Views on top of a query.
8276000	8288000	But I'm seeing this potentially building not just a knowledge management system, but an alternative social media.
8288000	8307000	Of when I say social media, I mean socializing part of it through these narrow confines, the boundaries, which help build and maintain communities and becomes the knowledge base for future generations in certain archival formats.
8307000	8320000	My thought, I only think that will add is that in our journey, we will find a lot of people who would be better positioned in taking care of the parts or aspects of some things.
8320000	8335000	We need to have these things in our mind in order to be able to like, yes, we thought about this, would you like to, the delegation part has to happen because there's only a limited amount of things that you can do it right.
8335000	8337000	Think of it from the last perspective as well.
8337000	8341000	The adaptation will have to happen.
8341000	8349000	And if we are having the community support right in the right way, then the momentum would not stop.
8349000	8361000	We just need to make sure the very minimal set of ground rules or baselines that we establish the platform that we create that is in well enough order.
8361000	8374000	Yep. So that we don't have to create keep on creating the patch rules in order to like keep the system same, which is a definitive indication of a bad system when you have lots of banded fixes.
8374000	8386000	Right. Yep. So let's focus on the core aspects of things and keep on showing the seeds. That's the one important aspect that I want to talk about is that we have shown a lot of seeds.
8386000	8390000	None of those things I see as actually a failure.
8390000	8397000	I think that even if they do not come materialize the learning from them itself is a something.
8397000	8412000	But I also do think there are options or ways to rematerialize them in a in a larger cohesive system where all those things integrate into a much bigger, much larger of a platform.
8412000	8420000	Yep. All those things actually do matter. So basically what that means is we are talking of doing the things that we do best.
8420000	8428000	Answer one potential answer to your question on session one. What is worth doing for us in our context?
8428000	8434000	What is worth doing is be the protocol people is be the foundational principles.
8434000	8442000	People is be the people who build the adapter system is be the people who build ways to build the RFCs.
8442000	8445000	Yes, we don't need to write the RFCs.
8445000	8457000	No, we need to provide the basic guarantees, identify those basic guarantees that such a system has exhibited to a certain extent through some early implementations.
8457000	8462000	The implementations would change, but to identify the boundaries of such a system.
8462000	8470000	And again, the things we understand best is how do thinkers think together, how to make thinkers think together.
8470000	8474000	And I think that is the place to focus on how to make them.
8475000	8488000	Yeah. And I think that is the focus we should keep, which means if the output of Anthropic Inertia are these videos, a set of research papers or articles or blog posts at its simplest.
8488000	8497000	Let's say a blog post. Let's start with simpler with a set of documents that we prepare on how a potential community can form around this.
8497000	8509000	Let me narrow down the scope. Software provider that provides certain code libraries to build systems on top of them.
8509000	8519000	I do think we understand DevTools so well, we can reason about DevTools so well that we don't need to reason about application level building.
8519000	8525000	So let that part be the topic of next discussion and I'll set it out in a sense.
8525000	8534000	Think there is a very interesting or curious case of gravity and magnetism in a certain way.
8534000	8536000	I'll explain why.
8536000	8540000	Hey, before you go, I just wanted to check. Was this a yes or no?
8540000	8549000	Yeah, I'm just saying that we don't need to jump the gun. We need to start the platform.
8549000	8560000	But I agree that we need to be the protocol people who sets the ground rules and ponders upon whether the ground rule is set well enough or not.
8560000	8565000	And interest, that's the reason I'm extending part of the discussion in the next session.
8565000	8572000	Not disagreeing, but in order to enrich that with enough point. I just don't think I should go into that discussion right now.
8572000	8575000	I'll end up exhausting myself. I'm pretty giddy, by the way.
8575000	8582000	Like if you don't, if you're not seeing, I don't know how it's coming along, but I'm like very giddy inside.
8582000	8588000	Like that it gives me like when I came out, I had lower energy state than I'm going out with.
8588000	8591000	So anyway, so I think with that part also, we discussed before.
8591000	8600000	Point is, how do we become the magnets or the black holes where more matter feeds in?
8600000	8611000	I'm not going to I am I am not going to expand more on that today as a matter of principle for the time because yes, let's let's continue that on later.
8611000	8615000	I do. I do agree on most of like almost all the things that you said.
8615000	8620000	I just don't think we need to start with that.
8620000	8625000	Like having the expectations. I'm not certain about the order of things either.
8625000	8629000	So because I'm just saying that that those were the instances of what we can do.
8629000	8632000	Yes, on all those records, right?
8632000	8639000	I just don't think the expectations need to be the driving principle because that's what that's what ends up being the dopamine feeders.
8639000	8650000	Essentially, you need to have a dopamine blocker in a sense that we should not live on the high right on the high.
8650000	8658000	We should utilize that but not ride on it because anyways, longer discussion again.
8658000	8664000	Coming back to the point, I think we need to section our discussion in particular parts.
8664000	8672000	And I think one part should be for the next couple of weeks or next couple of months should be that how does the platform ends up forming?
8672000	8677000	What are the things that are in the should be in the to do list and how do we approach this?
8677000	8682000	Because that is going to be a massive or major part by December.
8682000	8693000	We need to have the platform ready so that we can start promoting it out and have a reveal on the New Year's kind of way.
8693000	8696000	I think that sounds very good.
8696000	8707000	And yeah, I'm like building my handbrake and pushing the brake at the same time very, very hard.
8707000	8709000	Yes, time to slow down.
8709000	8712000	Accelerator and brake at the same time.
8712000	8718000	No, no, I've left acceleration. I'm just braking. It's a momentum carrying me onto the next.
8718000	8725000	But I think this is good.
8725000	8730000	Just make a note of that topic. I think that's worth doing things.
8730000	8733000	I'm not sure how much time I'll get in the week.
8733000	8738000	But yeah, next session, we can definitely focus that focus on that.
8738000	8744000	The only reason for me to like bring out all those topics and put it in front of you is that so that it goes into your subconscious.
8745000	8760000	So basically what made me pull my handbrake so hard is that is exactly where I had started my discussions with you a few weeks back with that in mind that I want to reach that stage.
8760000	8763000	So I think like it is converging up to.
8763000	8765000	It was always going to go that way.
8765000	8767000	Like I never had a doubt.
8767000	8771000	It's just that we need to be meticulous about it.
8772000	8777000	So we can't act on dopamine heat, essentially.
8777000	8780000	That's my point. There's nothing wrong with dopamine heat.
8780000	8782000	In fact, we should utilize that.
8782000	8794000	But that should not be the driving element, because if that becomes a driving element, then chasing dopamine heat ends up becoming the actual task we end up doing and not the end result.
8794000	8800000	So basically we need to identify where do we fit in, which you already explained.
8800000	8804000	And I agree with that part and keep on doing a better job at it.
8804000	8811000	Better job at laying down the real line and not.
8811000	8813000	I know there's more fun.
8813000	8815000	I just want to put one constraint.
8815000	8817000	I just want to put one constraint.
8817000	8824000	I think whatever we think has to be thought has to be evaluated on a larger time scale than we did earlier.
8824000	8828000	And I mean, like, I don't know how long.
8828000	8830000	I don't know if it is like a 10, 12 years.
8830000	8831000	I don't know.
8831000	8840000	But the longest basically the longevity of each of those things have to be evaluated and put priority over short term gratification.
8840000	8841000	Right.
8841000	8845000	And for that matter, we need a set point rate that jump set point.
8845000	8852000	So that's the part I was going to connect with the topic that I'm not going to discuss on the next next session.
8852000	8853000	Let's let's do that.
8853000	8857000	Because having a set point is very much important and having clarity on that is very much.
8857000	8859000	Yeah.
8859000	8860000	All right. Good.
8860000	8862000	So that's pretty much it for today's session.
8862000	8865000	I'm going to go ahead and in the stream and.
