I just spent the whole day pretty much bringing up my age-old blog site.
Last I had worked on it was I had moved it to 11ty because I wanted a good enough markdown to a good enough more text-focused site.
And then I have been trying, what I've been saying that I want to get back to writing.
So there was something very small happened at work so I started working with these people because it was the end of the project.
And one of the things that we are currently doing is figuring out deployment plans.
One of that was versioning strategy and I was like, at least let me write whatever we decided there because where it began was it started as a small tweet on Mastodon trying to just write the format that I had decided.
Then I needed to write another paragraph. Then I exceeded Mastodon's text limit. Should I break it down into multiple posts?
At this point, it makes sense to just write it in markdown on that blasted site where I have not made updates in years and put it there.
Then when I went to put it there, I first did it. It's connected to Versel so you need your deployment.
Then I log into Versel and I see a bunch of build failures. Sorry, sorry, it did not go through. It got blocked so I logged into Versel and I saw build failures.
And turned out it was set to Node.js 12. So Versel has deprecated Node 12. So this entire day was that thread.
And then it was, I have done this, I have done that. I might as well sit with the recording and start writing.
Okay, now that I have written, I might as well put it on the website. Now that I have put it on the website, I might as well do this.
So that's what I was doing till 1758.
Actually good, pretty good.
We are live. So yeah, I also have to do something very similar and I have written more, I started writing more amount of microblogging frameworks than actually blogging.
Every time I come up with this, this one doesn't fit me, I need to write something. There are so many names, FLOG.
The last one was named FLOG.
But yeah, I appreciate somebody at least putting things out there instead of just doing the procrastination behind it.
Even just for five years.
But what I mean is today is a historic day, even if it is the only historic day for the next four years.
Makes sense, makes sense.
So I was thinking about what you said and kind of trying to build up the idea.
So here's a thought. We have the right ideas, we do the right things, but don't, like we get, because we are too early to the party, we get lukewarm feedback about it.
And we don't stick around when the party actually kicks in.
We kind of, before that, shit this sucks and I'm going to go home and we just leave for home.
That ends up happening.
I don't have to explain that part, right? You agree that happens.
Now if we explain it will be for the audience and for the record, like FDR.
So I'll come back to the explanation part.
Like when those things happen, Applet is a good enough example, the AI, the things that we predict, this is where things will go.
These are the things we should build that also includes like, what do you call it?
The online communication platforms, Groupone and all, like very efficiently adopting WebRTC, seeing the potential in it.
All those things, we did it early, did it in advance.
It actually struck a chord with people who cared, but not with the mass.
It was not sustainable in that sense, that it wouldn't generate revenue immediately.
But instead of sticking out with that, we kind of like, ah, people just don't understand, let's do something else that is fun and interesting.
We kind of went through the loop of that.
I was thinking that that might again be the case, unless we are being mindful about it.
And this is a platform where, first time in human history, people are actually having discussions or interactive way of communicating.
Just basically not just one to many kind of communication, which has been the entire history.
Somebody tells you something and you do it, instead of that.
Now, I think my audio was still pretty screwed up.
So now, through those podcasts, audio books, like the comments in the video platforms, as well as the response videos like on TikTok and everything,
there's like interactivity between where people are getting their information from and sharing it, bouncing it right back at them.
And that is happening. That is actually huge from a potential perspective, from seeing a potential like what matters, right?
First time somebody like marked something on a card, something on a rock, it was not something that like it was not profound.
It was not really something that you would frame it and put it on a wall.
But it is something that you would frame it and put it on the wall for the sheer potential of transcending information through time.
Similarly, the discussion platforms that are happening that is like not one-dimensional, bidirectional discussion that is happening,
people communicating with the podcasters and stuff, that is going into a direction where I see a lot of people are setting up the base,
creating that ecosystem, which we can leverage from and bring in the discussions that people are yet not having.
We are having these discussions and we also think that, oh, maybe people are not interested about it or people are probably not going to understand it or whatever that is.
But instead of doing that, how about we give our best shot at making it available and whatever happens, happens.
My hypothesis is if we stick around with that and spend a good enough amount of building the backlog of what are the things that we want to talk about,
what are the things that we have at hand and the practice of it, then at some point when people have discovered it are coming along for the journey,
we will have a solid repository of stuff to show as well as solid grasp on the presentation of the topics as well.
And we can take it somewhere. It can become more than what it is now.
With that said, what are you thinking about this? Quick thought, it was just like I was thinking about half an hour before.
So this is a pattern that I anyway have found and I totally agree that the challenge with our work hasn't been really that we don't have interesting things to work on.
But I just want to say two things. One is my experience this morning, what I just narrated, how I got into fixing the site.
The only thing we need to do is look at something long enough, the way change, the way we trigger change or we work.
Sorry, that's like my cat's fur getting into the fans.
Basically, the way we have worked is if we look at something long enough, start seeing the cracks, start seeing the gaps in that and then we would like to fix that.
So this entire journey with Applet has been exactly that.
But the problem was that there were too many things to fix and we were like falling through the rabbit hole, not hitting the bottom.
By the time we hit the bottom, it kind of timed out. It was time to go home at that point and many other things at the same time.
But the point is that bottom, that journey, when I look back at that, there is a certain deconstructionist approach that I'm applying to that memory.
That how did we go? Where did we go? It was as if the quest to where it landed on unicorn, really, which was kind of breaking down to a certain set of fundamentals.
And I think that part is still valid as an area of research, as an area of research.
But the second thing here is that I have been already watching the last two videos that we have recorded.
This being chapter three in this discussion, and I see us intentionally or unintentionally overlapping topics, like the same things that we had discussed last time, that comes in through another area.
So if I was to archive this, what I found was there is one, of course, a narrative of as we spoke in the order of things.
But then if I blend that into like an encyclopedia or a knowledge base, so to say, by broad questions and topics, it turns out that we have a lot to say over time about the same thing.
And aggregating that would be very interesting.
So what I want to do really is with these discussions, I want to pipe this through to first us like speech to text engine, populate the basic.
And I mean, it's semi-intelligent speech to text, not just basic Python speech to text.
But that is where the AI part comes in.
The link that I shared with you, I had only gone through chapter one.
And as I kept on listening, I was also listening to last week's recording yesterday.
I was like, wait, didn't we discuss on day two and I'm watching day one?
And then I went to day two and it seemed like in day two, we have discussed everything about the topic, except the part that was touched on day one with some just common bridges, which means there is value in creating this union of sets.
And these topics are emerging.
What I mean to say is that whatever we repeat, whatever beers repeating in our discussions is something that we want to get back to.
And those should be the topics, which brings me back to that loop that I had said on the first chapter that if we are looping, then that is worth recording.
And that itself then goes on to form broader discussions.
So I totally agree in the sense that I think in the future, let's say even a year down the line, we could be looking at what we have done and trace it back to something like chapter two, chapter three, chapter four of the discussions to find that pathway.
This is good. We just follow where curiosity is leading at this point.
I think it's naturally emerging in a very nice way.
So when it's a curiosity time and whatever spark.
Yeah, yeah, yeah.
So I, so in that sense, let's not rush into packaging it and packaging is in sense like to make it something of a brand or anything immediately.
Let's go through the same process that we are doing right now with some patterns will emerge.
What you're talking about like the horizontal and the vertical interpretation of the things like we're talking about, like having a chronological.
Okay, we talked about these things today that think to the day after.
But also, if we look at from the perpendicular view, we talked about this part of this topic this day, and that part that day, and combine that as the topical discussion part.
So I have a wiki deployment. If that helps, if you want to also interpose as in, what do you call it, make it topical in that way order that also can work that way.
Yeah, I think that is phase two anyway.
Okay, I see. Cool.
Where was I going with this?
So, I was talking about how, where was I going with this?
I think I had a thought and it vanished. It popped.
Okay, forget it for the time being.
I think I understand what you're saying. I agree. Let the pattern emerge naturally.
Oh, the other part of it was about the speech to text part we talked about, right?
Speech to text, yes. So, there are a couple of services.
None of them are very cheap, cheap enough, as in, but...
I mean, I would measure it in my time, right? I mean, at this point, if I take three hours to get to a transcript, what is the cost of my three hours worth of work? I have a very clear idea.
I think it's more than that. If so, I'm willing to try.
It costs in thousands of minutes, and it's going to be $0.1 or something like that per session, ideally, something like that.
Yeah, I mean, anything under 15-20 is good enough.
Exactly. So, the better ones would be Assembly AI and second would be Deepgram.
And if we don't want all of that, if we just can run...
Do you have a GPU right now? Yes. So, which one did you get? Did you get the Intel Arc or did you get the...
I have a 4060. Okay. So, in that case, also, it's an RTS GPU. You can run the models.
So, those server services are also running, actually, the Whisper, the OpenAI Whisper.
So, if you run OpenAI Whisper, the JAX version, so I'll send you the details, right?
So, in that case, you can just basically run it on your system and get the result.
Yeah, so, I wanted to use the same opportunity to also learn at the same time.
The reason I created that space on my blog was I'm now like, I want this to be filled in this format, except I don't want to be doing it.
I want a script, help somebody do it.
But there was another pattern that I noticed by watching the last two recordings.
And that is compared to the last times we discussed this, there is a lot of higher order maturity in our thinking, because we have spent more time, both you and I.
Like earlier, what used to be vague jumps across the chasm, now they are like very well identified landing points and like we have traced.
So, what I mean is that certain things are very well formed and putting them together will probably be quicker than, let's say, it was last time.
What I again want to do is make sure that those inflection points are captured.
It's very much like watching two galaxies merge.
It's kind of that dance. You know it won't clash, it will just flow through each other.
The important thing is locking around that, like what you had said as twin stars orbiting.
I think it is looking like two galaxies currently merging and would then begin orbiting.
So, yeah, so last day we started talking about something.
Do you want to continue with that or do you have some other topics in mind?
OK, let's try to go for that. By the way, I posted the link about the whisperjacks.
So, if you can run it on your system, I think you will get the transcriptions for free, essentially.
Right, cool.
So, I was trying to make a criticism about dialectics, as in the entire process of dialectic, the dialectic process itself.
I was not able to put a finger on exactly where my discomfort comes from,
but finally I realized it from a concept called PID controllers.
Did I expand on this? I didn't.
OK, so let me share my screen then.
Can you see it?
I can't hear you, so you have to say yes or no.
I can see, I can see.
OK, fine.
So, this is a controller theory that is used pretty much everywhere.
You are trying to stick a landing, essentially, frankly speaking.
That includes the previous attempt of landing the Chandrayaan-2, essentially, the rover.
So, point being, there are three aspects to that control theory.
One is the proportionality control, second is the integral control, and third is the derivative control.
What do they do?
I'm not going to the maths part of it, just keeping it very straightforward and visual interpretive.
So, if you are trying to get somewhere, the intent of going there is, let's say, higher when you are not there,
further away from that position, the set point you are.
So, let's say, for example, this is your initial position.
This blue marker is your set point where you want to go.
Further away you are, the more intention that you have to get there.
But as closer you go, you have less and less intensity to get there,
because if you keep that intensity, you will cross over, right?
You will just shoot through.
So, you have to reduce that proportionally.
That's the proportionality part.
You can identify that as an echo chamber.
This is the thesis part.
Now, there's a drawback to that only using proportionality.
As closer it gets, there's a paradox with that as well.
It says you cannot reach the other end of the room diagonally,
because the arrow does not reach the target, because it has to get to the halfway point,
and then the halfway point, etc.
When actually you reach the other end, you never reach.
So, that actually happens mathematically here.
You asymptotically approach it, keep on approaching it, you never reach it.
So, in order to challenge that, you need a mechanism
that looks back at what the date is, the date it needs to pay,
and then it drives the proportionality up in order to reach that goal.
That's the integral part.
What it does is that it continuously checks how far behind we are from reaching the target,
and it keeps on adding an extra term to it.
So, the second part of that.
So, when you are getting closer, the proportionality of this value becomes smaller.
This value takes over.
The challenge there is the integral part does not have a self-correction mechanism for itself.
So, what ends up happening is that it shoots through, goes to the other end,
then basically has to come back again, because that part of self-correction is there.
So, when it realizes that, hey, I'm way off,
when the latency of looking back catches that, hey, I'm way off,
that's when it tries to self-correct itself and tries to go back.
But it results in a harmonic, as in oscillation, like it's basically a ringing,
where it never, again, it does not reach the set point.
It oscillates around the set point because it always has some amount of delta time
to look back on to identify that, hey, I need the correction, I need to correct myself.
That's where the derivative, so by the way, this integral term, you can look at it as the antithesis,
the term that tries to correct the proportionality, the echo chamber,
by bringing in the counter-argument and fixing the part.
The only thing is that there's also the exact same kind of latency that gets in.
And that's the part we actually talked about before,
is that we always end up overdoing any kind of social changes that needs to happen
when the discussion comes in, in a generation or half,
we basically overdo it and then we have to, again, go the other direction a little bit.
So, that's what ends up happening with integral term.
Now, what to do about this?
Another way to approach this is that the derivative term.
So, the derivative term approaches in a way that it has very little to no effect at all when starting,
but it checks for the delta it needs to reach around the set point and dampens the response,
sorry, basically the value by adding or subtracting the corrective term, that is, look ahead.
So, as integral part was look back, like how much we have not achieved what we should have,
and adding it to it, derivative terms like how much, how strongly are we gonna cross the set point
and dampening the response by that, and if that is not the case, then letting it happen.
Like, go fast if you are not approaching, but slow down if we are approaching that point.
In that sense, what it does, it basically helps us stick that landing.
Depending on the values, you still have that not, this animation would be kind of appropriate to see how it ends up happening.
There are more. So, basically what ends up happening in the ideal state is it goes straight like this,
asymptotically kind of gets closer and then touches it, and depending on the parametric values,
you get the landing, how closely it sticks the landing, right.
So, hopefully that made some sense. I'm not sure how much it came out in the diagram.
My point is, we don't have the third aspect in our, what would be an umbrella term for what dialectics is about,
or what dialectics tries to fix.
So, that part, this would be the third part that we need to add, which I'm calling it the hypothesis part,
which is look ahead, where do you want to stick the landing, looking ahead for that,
and then correcting the other two sides of things like thesis and antithesis,
gets corrected by the hypothesis and then sticks the landing, where it needs to be.
So, there are lots of like, I don't have worked for a lot of things, maybe because I didn't do enough reading about it.
This is kind of an original thought. So, I need a lot of supporting elements to build it up into a theory.
I'm done saying the things that I wanted to say. I am looking for the criticism on this part.
Yeah, I'm not sure you're going to get much in the way of criticism as much as a critique.
So, I do think, so when I said landing, I pretty much had something similar in mind,
though not, this is a good mathematical demonstration of what I was talking about.
And now I realize what you said last day when you said that hypothesis is the thing that's missing.
So, that connects back. And I do agree that in the sense that if we are to plot the rate of change of topic,
which is also what I was saying, that if we look long enough at something,
so what is worth looking long enough if something is appearing in the vision, then stay with it, slow down your approach,
and then invariably you're going to overshoot it a bit, then come back and land.
So, I think that there are multiple hypotheses on which I think we both are operating.
At least that is what I meant by a certain higher order thinking that has already happened.
Sorry, the reason we are not shooting off target really is that some of those targets far enough or fundamental enough have been identified.
So, I think it's a matter of letting down some of those hypotheses,
then discovering the hypothesis or articulating the hypothesis would probably be the primary focus of these discussions
each time with the aim to land the hypothesis in that sense.
So, your hypothesis is the blue mark and in the process some things will be things that we'll find solved.
Hypothesis is not the blue mark. If you go back to Hegelian interpretation,
the reason he came up with this is that the Father and the Son and the Holy Spirit, the Trinity,
he was trying to kind of symbolize the Trinity, which also Freud did with Ego, Superego and all these things.
So, that was kind of something everybody was trying to connect back with the theology of that time,
which I already identified or symbolized that there's a Father and the Son and the Holy Spirit and they form the Trinity.
From Hegel's interpretation, he said those three things like the thesis, antithesis and synthesis were those three things.
My point is that's not. The synthesis is the Trinity and the Spirit has to be the hypothesis.
The Son is the Id or the Son is the proportionality, the Father is the antithesis or the superego.
But the thing that lands the landing, that is the hypothesis part, that you need, that's the Spirit, that's the ego,
that's the part you need to land. And overall, they connect back as a Trinity. Overall, they connect back as the synthesis.
So synthesis is not complete without the hypothesis. What ends up happening is that we have not integrated that as a process.
In our, even till contemporary, we kind of look down on somebody hypothesizing something as you don't have solid data for it, right?
My point is solid data is only possible as an option for looking back, that integral aspect of things.
For you, if you want to stick the landing and not overdo anything, not do the damage, the only way to do that is look ahead.
And for that matter, you cannot have solid data. You need to have the differential part aspect of the thing.
So which is where the third aspect, the Spirit or whichever way you want to interpret is, that needs to happen.
So the overall thing comes as the Trinity. Overall, that comes up as the synthesis.
But I think that those three things, that parts of the Trinity are that thesis, antithesis and the hypothesis.
Together they make the synthesis, or together they should make the synthesis, which is much more nuanced than the previous approach.
I mean, in some sense, we are talking epistemology, so why not?
I should read this, as in I haven't gone through this.
So the epistemology that you would find in some of those Eastern traditions breaks down those concepts into further stages of proof.
So you look at Buddhist epistemology, you look at Nyaya epistemology, Shankar epistemology.
Shankar is probably the one who simplifies it in some sense, but it's Doito.
So it talks of two materials, which tries one nation, one election kind of strategy.
Everything is one. But Nyaya does this very interesting thing where it was a practice.
Now why I shared this, as opposed to Hegelian dialectic, is they are talking about the same things.
These are very, very strong similarities. But these were traditions who ceremonized their usual exchanges.
These were philosophies born out of people actually discussing, questioning each other, coming to the truth.
That is where Torco comes from. As it happens, if you look at the list,
stage number eight of the 16 categories is called Torco or hypothetical slash suppositional reasoning.
So Torco Corona is basically somebody says don't hypothesize. If you hypothesize, you are already on stage eight.
You're not far enough from actually achieving knowledge.
But these were basically the 16 categories. Now what these categories mean will leave that to coming outside of this entire thing.
But if you just scroll down a bit, like the overall epistemology, that you have perception,
and within which you have determinate, indeterminate, then you have onuman, so inference.
And these systems also standardize in some sense or formalize certain lines of inquiry that Western philosophy just ignores as voodoo.
But turns out there is enough, enough details in this schools of knowledge.
And you will find yourself very familiar with those. All it struck me when I read the first demo that this is how they have categorized.
I know all of these sensations. It's like they have presented me a curated, ordered structure to that exact chaos.
Now of this, these are like these are degrees of formation of knowledge. So Proman, which is the strongest.
So it says that before perception, inference is not as strong, but good enough.
Then you have upoman, which is comparison, which is, again, not that analogy, which is what you get to if you can't infer.
Then you have shop, though, which is testimony somebody else's words.
But the interesting thing is you can start this process outside in.
And if you then look at these three stages, you kind of again reach that sort of Trinity, because the hypothetical reasoning happens when you are discussing or when you are like that is where the dialectic comes in.
So hegel's hegelian dialectic and torco in there are kind of the other things you would apply to get to that hypothetical supposition.
But all I'm saying is that you're on the right track. This is and that was a bit patronizing.
But you're on the right track in the sense that I would just say that hegel is good.
Keep this on the other side and and keep the Buddhist epistemology on the other side, because what that says at its fundamental nature is you got to try things to believe it.
But if you don't get to try, what do you do?
You have to assume you have to imagine.
So basically, these all are people.
If you read those treatises, you find these people sitting randomly and asking what if questions.
Very little resource, which is why like my respect kind of goes out and goes for those people who have thought about these things with so little resources.
Because they couldn't have for the even the best they tried.
They couldn't have known all the other things that have happened, all the other people who are thinking the same terms.
So I kind of feel that we are so lucky that I can have a day job and also like do this for fun.
Right. Which is insane.
For many people, they had to live their life as essentially the way of living in order to even get any anywhere closer to this.
Which is also like I should not take this for granted, but yeah, it opens up.
But there is an earlier of that life.
I came to that. So this was my thought when I first studied this.
And this was for second year, sorry, first year, second semester of philosophy.
And my first thought was these people built so much exactly these words without so little.
And this was 2009. And I was like, if they had the technology today.
So we'll keep on saying this. But then as I learned more, I realized that these technologies, these are technologies to the point of understanding knowledge.
You apply these things to a knowledge based to creating a knowledge system.
And you don't have to be a product manager. These people have been your product managers.
You just let it implement what they're saying in these stages.
And because they work with such small data window, their computation is very resource conservative, not wasteful at all, essentially.
Which means the computations have been broken, broken, broken down to their smallest forms where they are understandable, then logically build up as a foundational system and highly technically interconnected sets of work.
So basically, I'm saying they were the product managers like epistemology is product management of knowledge.
Yeah, I see that. I see that. I see that form, essentially.
And I think one of the things I one of the hypothesis that I have been operating on is what what framework these people had created can be implemented using the technology that we have today.
Without the individual, because a lot of this practice then went on to the Sadaq.
So you don't then have to be the Sadaq. You can if you can outsource, you know, to the Babas that you have always wanted to outsource these decisions to.
Why not just like try a different Baba, a Baba that actually understands these things has been built with some like these technologies in mind.
But anyway, going too vague, what I mean is that I believe it is possible to build a knowledge base that employs these systems of knowledge and then, you know, build those views.
So given the same set of events, can I have a Hegelian dialectic view of the events?
Can I have a new view of the events, which are just different queries, different structured queries producing different kinds of data structures out of the same fundamental thing that you were seeing?
I am also seeing which is the nature around them.
Right. So that way, this is those all those previous prior works, they're basically stepping stones to go forward, go further.
Right. Absolutely. Yeah.
So that's how I'm seeing it. There are lots of these, these things, all these things should be kind of kept as like, okay, in the Appendices or the References section that, hey, this builds on top of these things.
In order to go forward, you cannot just have a solution and as a capsule and just eat it.
Basically, if you understand what are the parts it builds on top of, that gives you a better mileage.
So I think all the prior attempts, because the best they could do is build in the present by looking at the past.
That was the best approach that they could have taken, like very definitively, because we have to identify this thing as well.
What we are doing now is taking over of the derivative part.
Think about because we're closer to the set point. That's when the derivative takes up, like picks up the pace, because that's where it starts mattering more.
Right.
So we are bringing in that part.
And so far it hasn't been used as much because so far that that part of the equation was very miniscule and ignorable.
More what mattered mattered was the proportionality and the backlog of like, hey, we need to fix this thing.
Now, where to get to, we have a very closer view of because we are kind of reaching that.
If for the lack of a better set point, let's say superintelligence is the set point that we are looking at.
We are kind of approaching that closely enough that we need to if we don't stick the landing.
There are a lot of people are talking about what the dangers that like involved with that.
So point is now it starts mattering.
Now we are bringing that aspect, that part of the equation up and try to stick the landing.
I don't see the previous approach as the wrong or false or something.
It's just at that point, that's the best they could have done.
And at that point, those two are the things that mattered more.
Now that we're starting to matter the other way, let's make it more comprehensive and use the other term.
I just want to destigmatize the usage of hypothesis because if you look at it from even a school or childhood,
like if or even especially in we are data driven, whenever people say that,
what they're trying to nullify or invalidate is that somebody who is pitching an idea
that they don't yet have solid data for and to demotivate them from going ahead and gathering the solid data for it.
Right. So that's what ends up happening.
I want to destigmatize that part, that aspect of the entire discourse when that happens.
And overall, push it out into the system like the general side search or whatever you call it.
Is that the pronunciation?
To make everybody come to the conclusion that, hey, it is from temporal perspective,
we cannot only look at the present and the past.
Future matters just as much because the other parts of the discussion that we'll eventually come to,
where if you look at the actualization of the universe, it basically is a temporal loop in a sense.
It's like a rubber band. Where is the ending?
You cannot find where the ending or the beginning is if you start seeing the whole thing as a temporal loop.
So it is relevant to be mindful about the whole directionality,
the spline of time and not only just look back on one direction.
Yeah. Right.
So this is one of the topics that I want to kind of like build upon.
I'm pretty sure like we touched on this like two episodes like last time I talked about this.
This time I'm showing some of the data about this.
I'm pretty sure that there will be more terms and all those things that I will come up with and start enriching this particular topic.
This is going to be one of the topics.
Yeah. So let's put a pin on that and move forward with other things that we may want to talk about.
I have a lot of other things, but do you have anything else to talk about this?
I think this deserves a bit more elaboration just for the sake of.
Yes, what happened?
My headphone decides to go to sleep from time to time. It's grown old. It's like I have to go to sleep.
I don't think you are speaking through as in the mic change.
Essentially, the mic source changed.
Yeah, should be better now.
Yeah, it had I had reconnected, but it has switched back.
Yes. Anyway, I was saying that this topic deserves a bit more elaboration.
Therefore, we move on to others because there is some fundamental that this connects to to what I have been working towards and thinking.
And it's sort of right this time, right?
So the hypothesis that I mentioned that it should be possible to take some of these tools for mass consumption.
And when I say mass consumption, let me rephrase that.
I mean, regular consumption for myself and to those I want to share the information with.
I'm looking at the inside out network.
And for the same reasons that atoms form, then connect and the connecting force being a sort of gravity.
So what I see this possible like being possible to do is pretty much the same thing that if you look at Automarge, that local first project.
In some sense, my approach to knowledge management is kind of similar to their approach to dev tooling, where they say that if developers have built enough tools to make their life easier, software developers specifically,
the sort of debugging and things that don't exist for other technical professions.
Besides software design, because we use line based things and their premises to bring the same kind of things that clearly serve some small people are benefiting out of implementing within their domain,
bring those concepts and apply to a set of baseline fundamental tools that can also apply to other domains of creative work.
And what I'm trying to say here is that I feel like my approach to I mean, they have explained it in a certain ways.
I'm just using that analogy that I feel like there are all these different epistemological theories, which if you just look at them as investigations, queries and frameworks to understand, categorize, dissect knowledge.
I see different demos, those lenses that I had mentioned, right? Lenses of looking at reality are what each of these frameworks are.
So what happens? Instagram filters.
Now here is the key part. Each of them start telling you that there is a certain moksha, nirvana, whatever, orgasm, whichever stage, like there is a certain stage that you can reach if you follow these certain processes.
Now, if you break down those processes, study deeper, you'll see that they are very logical, very one after the other, very well structured journey, meaning that it is possible to reach that moksha.
And it's like a definition of done, that there is a clear definition in each of these traditions.
What do they mean by their equivalent enlightenment is the word that I was looking for.
What is the equivalent enlightenment in their traditions? What does that mean?
And as it happens, it is a lot of analytical data processing, sensory data processing, building up maxims, building up more and more compressed knowledge, which some of them also talk of the neoteny that you mentioned.
How do you get a crystallized knowledge but to retain the neoteny? That is a sort of moksha state or pre-moksha state for most of these systems.
But then my question, the my what if scenario is, what if we could codify these, do the computations and just try to reduce the time it takes to arrive at that moksha in maybe a scoped way.
So specific intelligence as opposed to general intelligence.
But it is possible to arrive at moksha, which is now if I just basically try to pass a data set through the kind of filters, they have talked of practices, they have talked of practices or loops, filters are well, like stages are filters.
You have to pass certain rituals to get somewhere or go through certain commandments.
It's a very well articulated system.
So if you can think of a flow, you would be able to map out each of these into very complex flows.
And if you then think of it from that flow based programming or functional programming concept, you should be able to build higher order functions, which basically form these.
And my hypothesis there is with or without AI, it should be possible to build the structural manifolds, which provides a sort of variability into existing data.
And then one of those views is like just a model that understands the AI way of looking at knowledge, which means it can categorize based on everything you throw at the knowledge base that these were the testimonies that you had heard.
These were the hypothesis that you had conjectured.
These were the inferences that you had built.
These were the experimental perceptions that you have had and thus this is the knowledge that you have gotten.
And these are, you can trace these back to these proofs with this much certainty.
The probability of knowledge happening is baked into these systems.
So not everything is certain.
You can be, you can get conflicting inputs.
So basically that is basically that some might be saying but it is probably a lower confidence score compared to you have touched it and you have felt it to be a sensory perception.
Again, sensory perception migrations and so basically I see huge value in taking this at least some epistemological thinking, which is again the past to address the challenges of the present, which is building them up into systems that can process data and produce meaningful outputs to actually build some sort of an emulator or plan for the future.
A sufficiently well-planned, sufficiently well-structured plan can be called an emulator because you can probably run it and play with it to emulate the conditions that might just happen.
So I'm basically starting from that hypothesis that what would it need to then build a system like that and turns out just that question has a lot of cross-cutting implications across the systems.
What is the difference?
What I'm hearing, what I'm hearing, not to cut you off, let's get you to do that.
Go on, finish it.
I mean, I'm just saying that maybe what you will be able to do is sum up that better.
Yes, so you're talking about the application aspect of this, which is the gradual next step anyway.
Once you have built up something that is solid, once you build up a tool that works, the next step is definitely application aspect of it, right?
The challenge there is I am very bad at that part or realizing when it's a good enough tool to be useful.
I am not interested in the application.
So to say when we say application, there is a certain application of philosophy.
When you are going into a debate, that is an application of philosophy, that is applied philosophy.
When you're writing a treatise, that is applied philosophy.
I'm saying there is a scope to build certain fundamental building blocks of software which exhibit these systems.
So just to map them out in just in the form of a framework.
Right, that part, got it.
Yeah, so when I say application, I'm talking of that.
I'm talking of it's like converting what somebody said as a proof to a series of mathematical equations if there is a logical flow.
So then what would be those components?
What would be like the building blocks of such a system?
And that keeps on taking me to a graph like nodes, components, actions, workflows kind of system.
And by now, so these were kind of niche, I would say in 2014, like flow based programming was like limited to airplane software design and all.
But now with the no code, low code thing, you see that everybody is implementing flows and kind of bringing back that part of things.
Which makes me think that we don't even need to build the application layer.
In the truest sense, we could be building that common API, that common library or the fundamental building blocks, which then, well, render using Unreal Engine, render using something like your user interfaces could be anything.
Build a game for all I care in which the learner is tested on Nya Epistemology.
Right.
The challenge that I am seeing here, the reason it seems like GPT-4 or maybe even GPT-5 or something like that would not readily be able to do this is because there's a fundamental issue of what their initial starting condition was.
And their initial starting condition was not to look at the world epistemically, the data that it has, but more.
I might be able, I might misinterpret this or say it wrong, but continue a conversation, essentially.
That's basically what it is trying to do by looking at all the data that has happened before.
Where the discussion goes.
Not really, it doesn't matter whether it's right or wrong or based on which framework can you decide or even approach it to be right or wrong.
And again, that Rajyuta Sharpa Brahm part, so I do see it.
What Google Bard has done is that it comes up with three different answers and lets you choose which one, which way of approaching it would you prefer.
Something similar can be done with various degrees of tunability where you can, for a model that actually is going that direction, where it actually has the understanding and interpretation.
If you want consequentialism as your preferred mechanism, then you go and interpret this this way.
But if you are more of a deontologist, you go that way.
And those two can both be the answers that you're looking for, depending on what your preferences are.
But it understands that, right?
There are some, so the models do, nowadays the models do understand those concepts a little bit, as in it will continue the discussion.
Claude does better than Chad GPT.
So Claude is probably the best one on that particular aspect.
But fundamentally, they are not built to, like for epistemic, they were built for just continuing conversation or discussion.
So that's where I see the challenge.
But it's not so much of a challenge.
It's just we have to wait a little while, maybe by the end of this year or early next year, by which time the entire, like the, we'll understand it enough.
But hey, now that we have done this, we have built the application layer of how to use these things or how to retrain them, how to how to fine tune them.
How to change the initial condition and what is required to do that.
Those parts will be better understood.
Once that is done, then we actually can build up a model that does exactly this.
In fact, that can become one of the co-hosts of this show.
And like basically fact check us or correct us or basically point our blind spots, saying that you forgot to do that.
Like you brought up the Naya Shastra into this, right?
That was helpful. That was yet another triangulation point.
It can do that much more readily.
Real time context that comes up, like whatever we're talking about, it comes, these are the things that already has discussed about these things.
And this is how you can connect it or there's a decoherence.
All those things can be approached that way.
I'm actually looking forward to that time that day, but I am not really sure exactly the process of how we can approach it right now.
It would take quite a lot of work to actually get that to reality.
Yeah, and I have been kind of hovering around this topic for a long while to the point that just what those fundamental data structures would be of such a system.
Because it looks like you can't leave everything to the AI.
You can't leave everything to the human.
And that is what these frameworks come in because they are a very well programmable set.
And just like being able to write that fundamental data structure in the way or not data structure, like the let's say the solution in a way that you have these nodes, you have
like you basically actions, functions, whichever way you put it there.
I have tried three, four different ways.
And in each of them, where the AI plugs in is as a very specific purpose, well trained computation on very narrow band aspects of things.
But again, this is connected to like my goal with this is, remember what I said that I want libraries to form as I continue living my life.
It's basically tying to that, right?
That retrievability is a very strong aspect of each of these.
So to continue to continue from that aspect, I am seeing a lot of positive movements on in that direction where the nebulas.
You remember I complained about that.
Hey, we have come to a point where I can write a node module and somebody somewhere in Serbia or Indonesia, people can just pull it and use it to the API that I have defined.
And it will be the entire ecosystem is very well formed.
But if I write a paper about something, you cannot readily utilize it in your math readily.
It still will have to be somebody who has to go through all those different people who are reviewing that.
Proving something had been nebulas and very much human dependent for a long part, a long time.
Now, some progress are being made to challenge that.
In fact, mathematicians are kind of getting frustrated about it.
What's what's the need for us in that case anymore?
So this is one of the I don't know whether this is going to be the winner in that sense.
But this approaches that and solves that problem.
How do you pitch a proof proof of something that connects from human to machine bidirectional rate?
So now systems as well as systems can prove things and present it to humans.
Humans can verify add or and or add addendum to that.
But all those things are possible.
This is huge in a sense.
If we have a deterministic system for proving knowledge.
And we can set the data point about, hey, these are the data points.
Now, those two things combined actually helps us get to the point that we're talking about, where there's a model that can do that.
Be assistive enough or basically just complete enough information, complete enough in that regard that we can go and ask some about something or introduce a new data point.
And it will have enough context to know which bucket to put it in, how to create the embeddings, where the vector location it falls on.
So I'm seeing a lot of potential there.
I wanted to discuss this, but like bring this one out since I discovered it, but didn't come out as an idea.
I couldn't remember it when I needed to.
This time I remembered it.
Look into that.
You might like it.
You're talking of the lean provers that you share.
Yeah, yeah.
The ecosystem around it or the same way what chat GPT made frustrated the school teachers, in a sense.
Similarly, this lean prover is making mathematicians frustrated in that particular narrow domain, fringe domain.
I just want you to just go through that and have that in your context.
When we're talking about these topics that hey, tools like this are either they already exist, or they would become relevant in upcoming time.
Think about Rust back in 2013.
Right, something like that.
This is the lean prover is like Rust back in 2013.
I just realized I had unmuted and then I went to speak.
I muted myself.
As it happens, I have tried implementing the basics in so many different languages.
I have a go version.
I have JS, vanilla JS.
I have sales JS.
I haven't tried Python because well.
But Rust is where these concepts just fit.
Even Haskell.
I have tried both Haskell and OCaml and it was like, okay, nice.
If I was a mathematician, I would have approved.
But with Rust implementing some of these, it feels like the language was built to handle these sort of complex low level systems.
And which makes like what the point I wanted to make is like Rust is the natural choice to implement any such things that we are discussing.
And then make use of the API, make use of Wasm.
You are opening up doors to pretty much every other reason for that.
Why did that end up happening?
I do feel like it's one of those critical inflection points, right?
That at a point when we are saying historically about the Rust project, I don't know.
I'm talking about why Rust ended up becoming this.
If you remember, it went through two sets of transformation, like massive transformations.
But where it landed, it seems very appropriate for this.
I mean, why?
The borrow checker frustrated people, of course.
But then the type system, the uncompromising focus on maintaining that type system, because it is the type system which makes it ergonomic to implement a lot of these.
The second was Rust deciding not to be just an unsociable nerd, but actually become sociable, get into that geek category.
And, you know, connect with other things.
So the API, the core was built from the foundation, like at least it's part of that, where it is possible to connect, look into Rust from other systems.
So connectivity from other, open to connections.
And then the incremental build that you were saying that it built upon the mistakes of the past while looking into the future.
But it learned the good things from the past, implemented for the present while looking at what future software can do.
I think I'll have to rephrase the thing that I was going to say with your information, because that makes a lot of sense.
What I was going to say is that it had the starting condition, the initial condition, what it tried to do, a kind of made sure that if it is successful to do that, it will end up in a state where it is ending up.
However, I realized there are other, let's say other languages, they tried to be purist in that sense, had very strong sense of like where it needs to go, etc.
But then they didn't get exactly the same way where Rust went.
And the part is, what you mentioned, being the sociable thing, like taking the feedback, be willing to change yourself well enough with time and with the requirement of people, even though it's not fun for you and it gets you down from your high horse.
It's worth enough to go through the transformation, go through the Laravel and PewPaw stages to get to that.
Otherwise, you get stuck in a self-loving, like echo chambers, like Haskell and many other languages like that.
They live that life. They're pure in a certain sense. And because they love their purism, that purism so damn much, they don't want to end up becoming what is popular by sacrificing some of the part that other people do not like about.
Where Rust actually did, like, OK, you don't like it that, like, it's not convenient enough. OK, let's make it easier for wider people, which helped.
Sometimes they even went back. Some concepts actually went back after making it way too like mushy mushy and then it's not landing well enough.
So that being willing to change with time and for wider spread basically is the fundamental aspect of what makes a species survive, basically survivalist approach to things.
That's what, along with the starting condition, because that is required. Without that, you again, you will lose your way. You need that.
But not being afraid to change with time, as long as you have your not star fixed. Those two things together is what got it there.
I'm pretty happy that one of the languages did, because usually what ends up happening, things that I put my bets on or things that I like, quote unquote, end up failing massively because of that extensive purist standpoint.
I'm really rather happy. I also came down from that extensive purist standpoint for myself and also saw that all the different projects or aspects of life that came down from that.
That transformation, that metamorphosis is what gives them the extra extended life that carries them to the next section, next phase.
No, no, no, Edmund, it's going in the same direction. Carry on, carry on.
I don't know whether to bring out yet another topic, but I have a couple of those things that I have been looking into.
So first of all, not first of all, in this particular topic that we are going into for that topic, sublist, for this sublist, first of all.
So I had a plan about because it fit. I have a plan about approaching three different topics and having three different names for the books called white matter, gray matter and dark matter.
So the white matter is basically the philosophy.
Gray matter is about the human condition, the psychological aspect of things, and the dark matter is about on physics, like the cosmology, et cetera, et cetera.
All those three things, concepts basically connect together. But that was the approach.
I'm not so sure because they're kind of like boiling down to the same thing, same part.
It's a little bit weird, but it seems like when you're trying to decide on the discuss on that white matter, the gray matter affects that your perception, your human condition affects the epistemic that you see and the interpretation of the reality also gets affected by that.
One aspect of that was the philosophy of metamorphosis.
Looking at the systems that are impure and impure the exact right way that it becomes advantageous to be impure in that matter.
Think about Voldemort as one example.
Think about the silicon as in doped semiconductors as one example, where the right amount of doping is what gives them the superpower.
Other than that, they are not super in any sense.
What is it about things that when we assign value to something, we kind of do that in a Boolean sense, we say something is good, something is bad.
That has been that entire moral and ethical schools of all different ways to think about it.
Aristotle did pose a kind of a middle ground, OK, too much, too little and just right.
I want to kind of expand on that just right part from the from the perspective of it does not live in a vacuum that just right.
Are you familiar with the concept that I'm talking about?
So just to just to for anybody listening to this.
So before Aristotle, like Plato and what's his name, Socrates, their philosophy was there's good, virtue and vice.
And they're kind of Boolean in a sense, good and bad.
Aristotle was like, no, here's the thing.
Too much of anything is bad.
If you are a person that is way too serious, that is not going to be registered as a good thing and would be beneficial for you.
If you're too much of a callous person, that also is not going to get registered as a good thing.
If you can bridge those two things together to come to a middle ground where you are serious enough but cheerful enough,
that is going to be give you the charm that people are looking for that is going to work in your favor.
So that's the that's the ground he was working with.
He kind of created nine of those sections and all those things, all different things that I don't think that set of like those nine items were comprehensive enough or anything.
But it establishes the point that you can see that in a spectrum.
My perspective is that you can still do that in a vacuum for any of the virtues, advices by themselves.
You have to look at it in which playground you are playing.
Carry on, carry on. You can get into this.
So the point I was trying to make is that you have to look at it in terms of where is this tool being applied.
And that's where that particular customization, which any of those attributes, any of the traits can be termed as good or bad.
But depending on the use cases, the utilitarian perspective, some of those things can be identified as advantages.
That's exactly what mutation is all about.
How mutation kind of promotes evolution and survival of the species.
That is the thing, the stochastic changes in some certain things that ends up.
So that's how evolution basically promotes, OK, go through multiple generations of things and whatever is supposed to stick around will stick around by just trial and error.
That's a very brute force way of doing something.
That is, evolution does not have a brain of its own.
But the way it ensures survival purely to its teleological own end, can you survive well enough to create another version of you with the good traits that you have and just loop that?
So how am I going to now come coming back to the talk about the entire part about the philosophy of halflings?
And then I'll go to the metamorphosis part, the halfling, the impurity.
So various different aspects of life in various different aspects of life, there are traits that people can use that gives them an advantage.
Or not only people like it transcends that.
But whenever you're trying to think of any of those traits in a vacuum, you can come to a like it's good or it's bad.
But the moment it gets infused with other things, other aspects of that, it becomes completely different.
It becomes either a necessity or a disadvantage in a sense.
Like a squirrel, you might not think why having a wing would be advantageous.
But if a squirrel gets the mutation of flappy like that handling the passive to support a passive flight from jump from tree to tree, how does that gives it evolutionary benefit to sustain its legacy?
That is stochastic.
It's a weird addition.
And those kind of weird additions are always there.
Usually we're not mindful about those things.
This does not live.
This entire concept does not live.
In a pure.
Interpretation of first virtual advice.
How do we frame that?
Because this becomes very utilitarian.
And that also might be a problem for some as in people who see things as a deontological perspective.
From that, they need to know whether something is good or bad.
How do we reconcile that aspect of things like sometimes there is no good or bad or there absolutely is we're just not looking at it right.
How do you think about this?
By the way, are you utilitarian or are you deontologist?
I believe in complexity.
And whoever gives me the complexity because I'm their slave.
Why I said that was that my gripe with most of these things is not about the.
It's not about if anything is good or bad or how people understand my gripe is the sort of reductionist approach of morality to constantly try to bring things down to.
Now, very polarized, very small set of values.
And what happens when multiple things interact, which is what you were saying.
I mean, I'm just adding to yours, not getting that.
The issue is that when some form of event interaction, some form of complexity comes up, that is when.
The smaller free thought framework, smaller, smaller moral frameworks break down.
Even if you progressed as much as saying that a good and bad are not two values, it's a spectrum.
You are still susceptible to the same thing because you are still susceptible to that one dimensional mapping of everything that is going on.
And. If anything, that generative is showing us is that to achieve higher and higher truth, better and better understanding and better and better predictions, we need to embrace more complexity.
We need to think in more dimensions, compute that many instances.
Now, what I'm trying to say is that this there is a certain.
There is a certain way of even building systems.
And I don't just mean software systems, a reductionist way of building systems, which in like, which wants to bring things down to this concepts of pure, impure, good, bad, impure being card, like the not pure existence of the not pure.
As often happens in that sense, the not pure happened to be the minority.
The pure happened to be the majority or the historical origins in which the pure happened to be the older, the non pure happened to be the newer.
So this line of inquiry, the slippery slope is it often leads to the kinds of bias where the system, the legality of the system is justified.
But the effect it has outside that system outside the purview of that system is often disastrous and disastrous to the point of no recovery.
Like there is a certain point of no return because you have simplified things so much you cannot trace back to what complex origins they were.
And that is when superstitions emerge or let's say xenophobia emerges and a bunch of these things can be traced back.
But then there is a certain value in retaining the complexity to a certain level.
So you are map reducing definitely because you want certain things to be computed.
But then the question is, what are those points of intervention in which the actor in this moralistic computation needs to step in and make certain micro judgments?
As opposed to be given a good or bad result. You can get a good or bad result if you want to.
And some of these concepts also underpin the reformation of justice systems that we see today around us.
The entire conversations around death penalties or around like mass incarceration that reform community work as a better option to mass incarceration, which like saves the state money and so on.
But if you look at the other perspective that what you are saying is that it's not pure and impure elements of the society.
I know I'm going towards society a bit, but just to draw that analogy that why diversity?
Why be inclusive? And again, connecting back to what did Rust do, which is where we kind of went into this from.
Is Rust embraced this resisting the reductionism, so to say, that it said that, OK, you cannot just say that these are this is the way to build software.
Everything else is irrelevant. What it did was set certain core guarantees.
One of them, one of those principles happened to be zero cost abstractions, which said that if I remove the runtime, if I reduce the runtime to near zero,
or if you're using just the same crust, you don't have a runtime, in which case you should be able to write your code in any form that you choose.
You want classes, you want excessive abstraction.
You can do that, but they are zero cost because end of the day, they are getting compiled to the similar underlying machine code.
Now, what that gives, if you look at it, it's very federal in nature.
It's saying that the core constitution remains the same.
You should try to stay as close to the constitution, but certain traditions are different for you.
You don't eat this. You don't drink that. You don't want this. You want these notable.
That's fine. You should still be able to run the same federal system without trying to impose on each other or take over the system.
So this is the sort of ingrained decentralized federal nature of also looking at community, of also looking at the systems.
The same thoughts build the systems, the same thoughts like the community first approach.
It's kind of like I described this to somebody a few weeks back that rust is basically at some point introverts, introverts in which ever sense, like socially awkward people eventually deciding that they'll do better work if they just for once work with each other.
They don't have to like each other. They don't have to party with each other.
They have to build RFs together. They have to vocally critique the work. They have to review the pull requests. They have to draw the roadmaps.
Wait, it's kind of like a wizard's convention.
So in that sense, rust is like United Nations done right.
It has a functioning product. It is not a body crippled by similar, very similar motives.
If you compare what is it that United Nations does not want to do, which is what makes its progress slow.
And as it turns out, if you were to make some drastic changes in United Nations to ensure certain actions towards climate change, they start looking like some of the things that the rust community has done.
Some point you have to draw a boundary and say no.
But at some points you also have to be accommodating, convince the existing people in the group that you have to let these people in.
You cannot be a roadblock. You cannot block their coming into the community.
But to those new people coming in, also sensitize them that look, this is the existing set of people.
Once you are in, you have to play by these rules and these are non-negotiable.
So, yeah, I mean, I was just trying to tie this together.
I see the point in like the connection between the two.
Yes. Yeah. So the morality part, what I feel is the question should not be one that of purity and impurity.
The question of purity only comes in the case of the conductivity.
If the purpose is verified that do we need a homogeneous society?
Do we need a homogeneous classroom?
Do we need a homogeneous colony, country or a homogeneous even software system?
In whichever way you think of it, it seems like if it is more result oriented, if it is more outcome oriented,
then the first thing to identify is the purpose valid.
So, for example, you say that we need only like certain type of people in the army for the army to function at its peak,
which then goes into gender segregation, racial segregation, caste segregation,
because upper caste people won't take orders from lower caste people.
So you have to break down caste, it seems, before you can have a functional army.
And then army is like, you know what, let's just hire upper class men or upper caste men.
That is one way to solve the problem.
The entire thing will operate very smoothly.
But unless you establish the purpose then and what I'm trying to do is bring in the complexity and saying that do not anchor on the end result.
Do not just evaluate the end result.
Evaluate the purpose, evaluate the process and compute the end result and have the heart, have the courage to accept that end result.
If you have put, if your process is well established, if your purpose is well reviewed and you are executing in a certain way,
be okay with the results because it's likely that you have not seen certain variables which might be impediments during your design.
This is called the agile way in software development, as it turns out, that be open to reacting to things, optimize process for people,
build processes for people, not the other way around.
And the reason humanity keeps on circling back on some of these core tenets is that it seems like if you ignore complexity,
you are doing the same kind of idiotic gesture that a hunter gatherer human just tries to be careful of the tiger
at the peril of ignoring the forest fire, which is I want to give tigers away.
I want to put fires all around me.
Tigers are bad.
So basically you don't want to go down that reductionism.
Now why, where this is the slippery slope is minds like your and mine can constantly self-check and stay on a certain blade's edge.
Even when conducting something which is just with two values or which is with homogeneous, there is that sense of alertness.
On an average, humans don't have that alertness, that self-correction is missing.
And which is why you see religious dogmatism pervade to the point because those are simpler frameworks to look at the world.
These people are not stupid.
They're not stupid in the sense that they are not capable of computation.
But you just can't compare a Pentium II processor, put it with a core i9, give them the same task.
I mean, not the right example.
Not the right example.
In a sense, I was trying to correct the analogies.
It's not about hardware, hardware.
Not about the hardware.
The software that is running is not does not understand.
Yeah.
Yeah.
I mean, in that sense, it's more like Windows kind of different.
It's a Linux version.
The exact same core i9.
If you apply the right software, it can work differently.
And what is the difference that Windows is trying to take a lot more decision for you?
Yeah.
What does religion?
What is the solace of religion?
Practicing religion.
It is computing.
So it is giving you a small set of model codes.
Precomputed.
Believe in it.
Delegating.
Limited customizability.
Yeah.
So what is religion doing for you?
I was trying to answer that question.
Would that be delegating responsibility in a sense?
It is.
Instead of trying to figure it out.
I'll do it myself.
And no, this is so that kind of goes into a discussion about.
Isn't there a saying about like know what you can control, know what you cannot control and know the differences, something like that.
It sounds something like that.
I'm pretty sure I'm messing it up in a sense.
So what it says that there are things that you cannot control.
Don't be too worried about it because there is also again overdoing that part and going into substance abuse and all the other kind of things where it kind of helps to assign that to a destiny or a God or something like that.
That's the part I cannot control.
Let let that be it.
Whatever that is.
Let's focus on the part that I can control and hope that my life turns out as something that I am OK with or happy with.
Or I can give myself the illusion of that's the best life that I can have.
That pretty much where it boils down to the entire concept of worship.
Why would you want to worship something or go back to like.
Basically sign your free will away in a sense to some extent.
If something happens because your destiny wanted it to be.
That means it's not that you that changed the destiny but destiny wanted your path to go that way.
So that is kind of signing off signing away your free will in a sense.
Why would you.
Again it doesn't matter where I stand on the free will part like the.
Keeping that aside I'm talking about in general sense.
So that's where the concept of this entire.
So that results into a broken self regulation.
If you are expecting somebody is doing the regulation.
That means you are not responsible or liable for the regulation.
And what happens when we don't use a particular muscle.
It atrophies right.
So that's the same thing when you are talking about the part about being able to work or like walk on the knife's edge.
And not being able to why that happens why people don't.
Like most in general don't want to or can't or fail to walk like walk on the knife's edge because they lose that muscle.
They lose that self regulation because they attribute the delegate that self regulation regulation part itself on somebody else.
And I'm not talking about only on religion.
It does come down to the regulation of the justice justice system etc.
It also does come down to that is the comes down to the governments as well.
All the system where you need to look up to somebody like a big brother or a father figure in order to get something done anywhere that is.
That means you are weakening yourself.
You are not just a small political commentary at this point is this is the part I feel like resonates the most with Ambedkar warning people about hero worship in Indian politics.
And he was kind of talking from this delegation perspective as well that we are prone to doing that because it is easier because it is convenient.
But yeah end of commentary the curious part though in all of this is that you can in fact live your life in binaries but just wanted to tie this up to one of the maxims of life for me.
I think I briefly touched it on last days be wary of binaries and I mean be excessively skeptical of monogamists.
And in either sense the reason for that wariness is that it's OK to walk on that knife's edge.
And again each of these systems that we are talking of what are they trying to do the role they play in a human's life.
They are sort of a competitor to religious beliefs you will find at every step whether they mock or ridicule or this they claim to be delivering an alternate lifestyle to what everyday religious practice is granting.
And that is in sort of the complexity of things but how it grants is it says that you would eventually go back to doing the same kind of things.
You would eventually understand what is good or bad what is the self what is the other you would end up with this knowledge of binary but by then you would have learned how to compute the binary.
And walking on that knife's edge is then that balancing act that you are doing constantly evaluating checking yourself that are you at any point transgressing these boundaries which should then call to question your final decision.
Which means it's saying that with enough practice in a certain form humans can be better model like more moralistic creatures be able to compute good and bad quicker because it also can warns you about the non-computational complexity owning problem that you suddenly expose yourself to a lot of complexity and you hit that numbness the indecision.
So for these traditions the goal is not to stay in that indecision but to be decision makers very fast decision makers very intuitive decision makers very decision making is backed by these things.
So you're not offloading that computation unless you're offloading that computation to certain systems which form under this and that is where their proof of knowledge their way to motion all come in basically they're saying that you can if you want to be the dharmic some say that some say that you be the ideal citizen.
Most of these are chasing ideals in some way or the other and that ideal is that blue line you know that that is where you want to be they're first pointing that out so they begin with a hypothesis.
No that's not a hypothesis that's the set point that is.
I'm saying they begin with the hypothesis that we want to be there let's first prove our intention it's at the starting point it's like saying first you do you think you want to go first figure that out before you start on your journey you don't want to be lost so you start on your journey look up the map do your research then start walking.
So then you start approaching that curve so basically in this foundational work a lot happens in that part before takeoff.
And that is the initial state basically the valid verification and validity of that initial state is just as important for them to then say that you will go the right way so they're basically putting that computation there charting your path then letting you go.
It's like if you then follow the trajectory it's like Chochandra and three right with minor remote commands you should be able to land in the right place but the computation is done before launch.
My interpretation of that is it starts the way it starts it starts holding hands of a very limited set of entities that wants to head that way over time more associations come in and gives it the momentum it needs which is why it gets closer.
Now the only challenge is again I don't want to like harp on that particular thing for far too long the proportionality part of things it basically whenever it reaches close enough it basically loses the interest we got almost there so I'm not interested about it anymore.
In that sense a lot of people have become comfortable at the 80% like reaching 80% success and be fine with that that's when you need to find the people who are like no this is not ideal we need to pull it out and that's where the integral comes in.
So again not to dwell on that but I think that's the way it's not about pre-planning the whole thing before the journey starts that's not even though I prefer it to be that way the planners self would want to be that way usually.
You are like identifying the stages like the root so to say.
Yeah I'm saying that somebody just starts going that way gradually more people join in and figure that part out the plan on the way usually that's how pretty much everything like the all the revolution that's how it happens.
The plan is not set in stone and it's not that if you if you keep it that way and don't adapt with changes you're actually going to have much more much of a success you're actually going to fail because the reality is much more messy and chaotic than you can plan out to be like complete details right.
So the part the part of the other thing is that it's not completely planned out from beforehand somebody some entity some particular person that wants to leave a mark on the reality starts heading on one way and either they get the momentum to go that direction or they don't.
For any kind of set point approach you see there's thousands of set point approaches that we don't see because they fail right.
So that was the other point that I was trying to make from what you are saying I was I don't know whether it goes as a correction or an addendum but that's how I'm seeing it the way it starts off the journey starts essentially.
So what I meant by charting the route is basically identifying intervention points possible intervention points having certain event based thing you know like I'm saying I'm just telling you how the systems.
How I'm saying how this knowledge systems work so when they are how do they do research so basically when you go into the AI and I'm talking about okay so my way when you do that is I was saying that when you do that how the approach is broken down it's basically the question of how do you acquire knowledge.
And you are talking about subset of people who are into this yeah I'm talking subset of people who are understanding was my thinking the mass yeah so my question and this is my lifelong question is that how can I that is what you're saying that how can I take what these people know to the masses that what would that look like that was one of those hypothetical things that I had.
Good but that was the question I wanted to pose it now I just want to wrap this up this part of the discussion and I think the final thing to mention here is he.
The important part then in the human machine interface conversation.
Becomes identifying like having that ability to.
Becomes identifying like having that ability to synthesize from a hypothesis that is put to action by actors of certain sort like the thesis and the antithesis being put to work contrasted with the hypothesis.
But the part that I agree with you is that the obvious expansion to hegelian dialectic is the ad that the synthesis is the goal.
Formation of it is not.
And you want to introduce that hypothetical state.
At which point you have a I don't know if it is more is it like but at that point you have more of a new hegel hybrid.
In the system.
And what I probably harping on a bit too much not to fan.
Because I know that I'm taking one example philosophy actually does not de stigmatize like that that hypothesis yeah so that is what I mean that Nia is most most eastern traditions do not stigmatize hypothesis in fact they encourage this is what I was trying to say yes.
These traditions encourage open ended skepticism.
And they say that open ended if you do a close ended inquiry close ended inquiry being tracing back from God.
Yeah, you have already gone to the farthest extreme and you are coming down.
That is where things are prone to reduction reductionist approaches.
But if you go inward out, which is what they mean by saying that no Brahma by knowing yourself.
So what does it mean by to know yourself is your first knowing your surroundings and you're working out from that and these two create very interesting differences.
The inside out tradition is a farmer synthetic tradition far more inclusive they result in frameworks which want people to come in study observe be together build.
You know systems to work with them better.
Whereas the other one leads down to more our majority is in danger kind of attitude.
Because it has already known the extreme and everything then has to fit that narrative or it will be forced fit.
At the cost of boxing out removing the impurities to make it pure.
And this very interestingly again a lot of American queer politics uses language which is very reductionist in that sense and you end up with labels upon labels taxonomy done reversed.
You are constantly breaking down one segment into 10 others.
But first you must have that one segment.
It's not like when you've identified there are 10 subsections within this one section you now say that okay this was a wrong categorization.
This was premature categorization.
No, it has to be a like directed acyclic graph of some sort.
I think I see the pattern in this and the reason for that.
Why people go that way.
So I sent you that Joichi Ito article.
I have it on my reading list.
I have I have certain opinions.
I want to know your take on that the problem statement you might not agree with the solution.
But it's the problem statement which you might find very dear to might I don't know.
The second link I sent is somebody else's critique of that work.
Do not read that till you feel like you have a good enough idea.
Got it.
I mean if you don't there is nothing you won't understand because it's primarily HCI.
It's primarily UX.
Okay.
The last point that you're trying to why reductionism pops out.
Why it ends up going that direction.
This is part of a bigger discussion yet again yet another topic.
And I know that for a past few sessions this will keep on happening.
So basically I think it will continue.
Yeah.
But the origin of religion itself you see there's a pattern to it.
It starts from the void and the highly philosophical the spiritual interpretation of energy something from nothing etc etc.
It quickly goes down into fundamental forces of nature as the gods.
And then it pops out as there are one one thing that matters more than all the other ones.
And after saying the general principle let's put that into perspective of Hinduism where initially you start with void.
There are three different gods that basically pops out over time.
It's not even like solidified in a once and like if you go through the purans and so you will find multiple different interpretation of that.
But eventually you get that OK these are the more philosophical standpoint of a fringe.
People at the end they have nothing else to do but think more deeply.
I mean specifically Vishnu Purana.
And before Vishnu Purana is where it's kind of transitioning like hey we need to convey this message to a little bit broader audience like the kings and the people in power.
So basically it's going out of the hands of scholars.
Scholars were fine with the very spiritual interpretation of it like the void and so the duality etc.
But now you need to simplify this for people who run countries.
The nations essentially.
So now you're trying to convey that message to the emperors.
How do you do that?
Now your story will revolve around creating the gods that are emperors and or their sidelines.
So now Zeus from Zeus like Norse mythology all those things even Hindu mythology like Indra and all this.
Now the story revolves around the fundamental forces of nature like Vayu and the sun basically the air the earth the power of war like war gods etc.
All those things basically come into the picture and that's the interpretation because that's the demography you are trying to reach out to.
And then the third level what happens is that is the mass is still out in the void.
They're basically the life is misery and there's no end to it.
You are living in that situation.
Somebody comes out says that hey look all those interpretations.
You are not in a position to understand this because you have been left in the gutter in your entire life.
Without the resources to actually reconcile with those concepts that they're talking about.
You don't have the tools or utility and you are in the part where you are at.
You are at a position if what position I'm not finding the right word for it.
Like you are your life has come to a point where you cannot go back and pay those debts and pick up the books and learn everything and then get to their same level.
It's not possible for you.
You need a simplified interpretation of this for you.
Those what do you call that thing like the Monashat Mongol and the story of the small gods story of the one God essentially like only focus on this particular guy.
And he basically he or she will basically take away all your pains.
That also goes down to all the extra bad as in the monotheism concepts as well.
Is that forget about the complexity and nuances of all the whole other things the way they have tried to interpret it for you.
Just this 10 commandments and this there's only one God.
That's all you need to know.
Life is easy delegate that decision making and self correction and regulation which you were not equipped with to begin with.
Now this your life is now much easier.
Go ahead.
Now all those people for all those people life is actually much easier because it takes away the pain takes away the confusion.
If you are having a misery because God intended that maybe you have done failed at one of those 10 commandments.
That's why you're having misery.
Anyways and for everything else all the carrots and sticks aside there's the ultimate one carrot and a stick heaven or hell.
So basically even if you feel like you you are going through the life not being punished for bad work or not being rewarded for your good ones.
You still keep on doing it because at the end of it there's a.
So all those things basically comes down to that reduction is the one one God one dimensional belief or worshipping tendency goes comes down from.
That entire part of the how do I I if I don't want to take responsibility for all that thing understanding all that thing or regulating myself.
How do I delegate that whole thing to a one particular God that I believe in and then it goes down that way.
So I'm not saying that it is only about religion.
It expands in multiple different dimensions including the ones that you have mentioned.
I also understand the paradox or not paradox the irony of me trying to reduce down the whole complexity and nuance of religion like the entire theological institution down to like OK.
Hey there's only three sections.
That's that's pretty much it.
I do understand that but sometimes you need to get a picture of a place to read as a memory and you cannot have the entire 3D model of the place that is not practical.
So that's the only reason I'm doing this.
But I think I guess that's how it ends up happening.
For some people just living with that like getting the really pain relief is not sufficient.
They will keep on running around trying to find more data point more and more at the cost of pain to look at more complexity to assimilate more complexity and find out a better model.
And they will take over the responsibility of regulation on themselves and some else would not want to do that.
They just want to have a happier and less painful life and they would want to delegate that.
OK, I'm done on that particular aspect that particular topic.
You sound that a better assimilate the complexity and find a better model.
Is the fundamental principle to build upon to in order to resist reduction.
And you're right that it takes a certain amount of madness to throw yourself constantly into the face of complexity because it is painful to the point of being physically painful depending on what you are doing.
But like the more complexity you embrace.
The key is to not stay in indecision.
There will be periods of indecision.
The key is to know how to break out of indecision.
And that is the assimilation aspect of things.
The only way you break out of indecision in the face of complexity is if you can assimilate the complexity into as a patch on your existing model and improve that at which point you have reduced.
So like I said, it is resisting in many sense the idea is to resist reducing but not stop doing it because MapReduce as a function is vitally important.
Which again, remember what we said in first episode that what is important is to store this MapReduce values, but also the computational like some sort of a theorem, be it a theorem or be it like an version control snapshot in some way to prove.
Those are the edges. If you see the node and edge aspects.
The reductions are the next set of nodes, but the process through it like if the function that it happens through it are the edges that connects them from.
You take this data point.
This is the function that you apply and you come up, come up over there.
If you apply a different function, you go somewhere else.
But knowing the intersection and interaction between them is where you cannot say that this one function is the rule them all and others don't matter.
That's one way. That's basically where the criticism I was making right now is that that's where people tend to go because that's easier.
So now from an HCI perspective as in human computer interface, the UX considerations, not just UX.
In fact, let's just call it interaction perspective, right?
The producer or the controller of the system goes from higher complexity to lower complexity.
The consumer of the system, the viewer, the accessor, the learner goes from lower complexity to higher complexity, traversing the same paths.
Are we going into that entropy discussion again? The designer entropy comes in every single time.
Entropy exists everywhere.
But what I said is no, no, I am not.
I'm just arriving at it.
In fact, I have I'm just starting back parts I have taken already, but it fits.
So basically the HCI considerations that you need to do is that your system needs to take in all the complexity, be constantly map reducing to give you the simplest set of values that can be portrayed on an interface.
So when you look at it, you look at it as the world that appears.
It appears as a world and apparently benign, devoid of details till you start looking into things and there are infinite layers upon layers of details that you could go in.
And this as a interface design principle, ever since I realized this has built possibly the best possible APIs, best possible practices that I could ever dream of.
Because connecting this back to API first, the idea behind API first design is not that you first build the API, then you think of what happens.
Now, it's about you identify all the possible variations in the system that can come in, identify the interaction points, the map reducible points, understand what to do with the end result and how to map this.
How do you hide this complexity?
Like it's like showing the map reduce result first, then showing the computation, then showing the input values.
What's wrong with that?
No, I'm saying not wrong with that.
This turns out to be an excellent API design strategy.
Yeah, I think so because think about it also from like, I hope you don't have other things to add there immediately.
I was just reflecting on that.
If we are talking about a new child, like in a sense like a new human trying to make sense of the world, how does that person start?
They have to start from a present.
And whenever they're curious, they can go back and look at how it came to be that tracing back your point.
The point and I also agree is that there needs to be the trace back point.
Like how do we get there?
The entire nodes and edges should be there, retained in a sense that anybody who wants to, who's curious enough, can go and check that back.
Most people wouldn't want all the paths, wouldn't check all the paths or wouldn't find the energy to do that.
Which is not like the point is you cannot force people to know you have to go read this particular like 5000 old year old book first.
Then only you get to come to like eventually understanding like the present.
You cannot, which is how I was taught philosophy that that is the chronological view.
Yeah, that it just doesn't fit.
It doesn't fit.
It is.
It is.
It doesn't fit even at a small scale.
At a very small scale.
Because the realities are so different.
Yeah.
The perspective is different.
And how do you expand on the perspective?
Take any of the quirks of our all those mega novels.
What do you call those things?
The Ramayan Mahabharata or like the epics, right?
So any take any of the quirks, right?
Why this is happening?
Why Vishwa can steal two women and get them married to his brother or whatever that is.
The point is, it seems like from our value of the present, it seems weird.
Now, if you ask the question, then you get the answer like further down the line.
Given that socio-economic situation, these are the things that were considered heroic or good enough.
Like it's not considered.
And then your understanding expands.
But what if you are forced to understand from that word first, as in from back to now,
your understanding of current would be super messed up.
Because at the highest level, you have a limited set of memory.
Memory is still as in memory in the sense of the compute element.
I'm not talking about the raw memory.
I'm talking about the amount of new neurons that you are working with.
That's limited.
Now, you can have somewhat functional model of the world view, the womb belt,
and then keep enriching it with more details as you find something interesting.
But if you start from the beginning, you already have a weird sense that weird model that doesn't fit now.
And then you're trying to retrofit it to a current model, which is screwed up.
I've seen this so many times and it frustrates me all the time.
And the challenge is to have this conversation with any of the systems,
I have to come from so far back and have the ground level discussion of so many things
that it doesn't make sense to have that discussion at all.
It's just like, okay, table flip, I'm out.
Basically, that's what ends up happening.
The table flip does not happen.
It happens inside my head.
Yeah, it just doesn't happen because it's that much more difficult to recreate the table in its current position.
Imagine if you could just reset.
But I just realized, I keep on saying that game design has a lot to teach the rest of application designers in software design.
And if you look at it, the good games embrace this philosophy that I just said,
that the designers design from a higher complexity to lower complexity.
The player starts from lower complexity towards higher complexity.
The games that do this the best to don't have a help panel.
The gameplay itself teaches you how to play.
The one immediate, two immediate, three immediate.
Okay, I can give multiple examples.
Portal, the starting of Portal or Half-Life.
Well, not Half-Life in general because Half-Life kind of started off from a certain...
All the Valve games.
All the Valve games.
So basically everything built on the Valve platform.
But Portal specifically, Portal 1 specifically in the way it teaches somebody absolutely not used to computer games,
not used to these controls to move.
And part of the story, and this is where the design from higher complexity to lower complexity,
part of the story is in the beginning telling you, it's okay, you're not able to get the controls right.
You remember that you're disoriented.
You just woke up from this cryo sleep.
And the validation it gives to the learner, I am not supposed to get it right immediately.
These things, unless the designers thought of the complexity that somebody might not even know the controls.
Have you played Stanley's Parable?
No.
Oh my God, you're missing out.
Go play that immediately after this.
Right.
Or maybe first read up on that.
That would give you a better mental.
Otherwise, it's going to feel a little bit frustrating at first.
But read up a little bit and then start with it.
You are touching on that point.
I just want to have that levels, the organic level of like, where does it land?
How Valve developers work and how much self aware their games are.
Stanley's Parable is an ode to that.
Like the game is made to be a self aware game.
I don't think you need to read anymore.
Just just go ahead and install and play.
So I think you're missing out if you don't play that game.
You will.
What you're saying is correct.
It's right.
You're just missing out on so much fun that I think you should enjoy this.
Yeah, I agree.
Basically, I'm trying to apply some of these into software design and ask these questions.
One of the reason of me trying to get out of the standard corporate ecosystem was I wanted to.
Now, it's time.
Like I have spent enough time doing application building in general terms.
I'm still doing that for money.
But the point is that I see software from this perspective that there are so many other challenges
for which certain solutions exist.
It's not like I was the first one to invent this.
It's just my observation that I am presenting here.
What that observation says is there is enough scope to bring some of these concepts,
apply them to certain other domains of human computer interaction or machine to machine interaction.
Interaction design fundamentally escaping the confines of a screen, escaping the confines of just a small software
being thought of as these interaction points in the world around in a broader context.
What does that mean?
And then what would it mean to even add with the current day technology, the immediate step, let's say,
because I think there is a scope to build up to this.
What is it that we can do today that in 10 years time have the last effect on making some of these ways of thinking more mainstream, more mainstream?
I am not saying I want 100 percent saturation, but I want to the level of saturation that let's say rust.
In fact, that's the point.
Let's not set a popularity as a matrix.
I don't.
I don't.
So I am like enough validation across a critical threshold of survival, beyond which it's propelled by community effort.
To the point I want to see these discussions manifest themselves to a point where they become the building block for the next generation to build on.
That's my goal.
Yep. OK.
I don't know how much time you have, but let's say that we have 15 more minutes.
I'm trying to find something, a chain of thought in five minutes.
I'll not give enough explanation.
Carry on, carry on.
But I have time to think over the course of the week.
This is how I'm thinking about this.
I think there's merit to bring this entire discussion, all those things as a platform, which we started with talking about.
But let's start it, the start of brink of new year.
And until then, we can have our practice runs of jotting down or basically get our ships in order, essentially.
So tell me, what does such a platform look like?
It doesn't have to be too much critical.
Basically, I already have something that is going.
I can reuse the anthropic inertia is one of the platforms that strikes me as the most like non.
I mean, to what end?
I'll come, I'll come to that.
To what end?
What is the end result of that is?
No, what are the end products?
That's what I'm coming to.
I'm talking about the brand first, because then I'll come to the product, like aspects of the physics of it.
So void was more of a like it was mischievous.
It was not welcoming enough.
But that's why I have multiple aspects of the anthropic inertia is the one that is actually it is a reflective platform supposed to be.
Yet it is not unwelcoming.
I have posted some things there, but I don't get enough time to do more.
Anthropic inertia has a YouTube channel, which I messed up a little bit with contents that I don't want to post anymore.
So very linear content.
It doesn't have the longevity, essentially.
But it also has a Spotify as in the podcast aspect of it, a sub stack and Spotify and Google Podcast and all.
So basically it has a podcast and it has a blog post.
What I usually do with the thoughts, like things that I've done so far is that I come with this come up with a script point that I want to make.
Then I write up about it, publish that on a sub stack.
I use my voice model to read it out loud and use that as the podcast for this podcast platforms.
I haven't started using the videos yet.
So if those audio we take the audio and generate video out of it and post it on YouTube, that can also be possible.
Point is that not the video point is the sub stack and the Spotify basically podcast subscriber model where people can tag along.
They basically press a button to let you know that they are with you.
They're listening.
So if there's what are what to what end, that's the end where people can give you signal that they are listening.
And then have a community of that where the discussions that we are having are having a second or third order harmonics resonant frequencies at that at multiple different levels.
Once we start establishing that, I'm again brand name.
Forget about that. I'm talking about the anthropic inertia is a perfect 20 to 23 company name or organization.
It is a good brand exact extent, which is why I come into the realization.
You even went with the acronyms mapping to AI.
Yeah, you see that, right?
It's not that unobvious like I know that you would say, but yeah, so those things are basically prebaked.
I see that it has a massive potential.
Let's do it right this time.
The right is in the sense.
Let's not be too hasty about it or look for fast gratification.
I know that it's going to take some time.
And given my calibration, like understanding of what happened in the past, it takes about two years for things to catch up to our expectations.
So maybe we would be we would have enough time to prepare ourselves to get to the point where enough people are listening.
So we need to be on topic.
Which is which is fine.
Something else struck me.
And of course, I'm the one that jumps the gun.
Exactly five minutes.
I'm getting a lot of latency from your hands.
Sorry, you have been eight bit there for like an hour.
OK, sorry.
But the video is video is much better.
You can see it on the end of 40.
I know the recording you're recording on your screen.
Yeah.
Yeah.
So that's that's fine.
So I watch the videos.
I've been doing that for the last two weeks.
See, I see the entire thing that you said, the application, the applicability of converting this into carving out an application from this.
If it is again, just to see scratch our own itch.
I kind of see.
And this has been going on for a while.
There is a sort of merger of Kong's future version, let's say, which is up speak as the knowledge management system to a lot of people have been talking.
It probably came out the closest in your analysis just now that there is a gap for this creators platform.
Where knowledge creation or content creation has too much emphasis on quick creation, linear flow and so on.
How can we bring in complexity capturing thought processes to broadcast to audience engagement?
I'm kind of combining up speak and X flex in my head at this point.
I am no longer seeing those things as separate units, but basically a plumbing layer that again connects these things.
And if we build outside in, which is we start with the videos, we learn the audience engagement and build from there.
This will come up to with the knowledge management and these principles in place.
I see the following possible hypothetically.
There are discussions from the discussions just like this, whether we stream or not.
I can see a complete cycle, basically a very forward looking.
What's that called? Progressive loop.
What is the loop that adds value? Positive feedback loop.
So I'm seeing a positive feedback loop possible that start with this broadcast.
You get incrementally better. You narrow down your topics.
But these things being taken, the contents grouped into say a wiki, which go on to inform certain other discussions that others can participate.
Parallel forks of this conversation with parallel things other people doing, which can be merged, the synthesis of the idea where each contribution can be traced back to its origin story.
That basically community as part of your subscription.
So how do we bring you remember that was a problem statement to solve with Kong that how do you bring people who are listeners onto the platform without disturbing the flow is still a very interesting problem to solve here.
But I am now saying instead of that just being a real time problem, I want to make it a semantic problem.
I want to make it a very well deontological problem.
Yeah, you are deontological.
No, no, no.
I'm just saying that when I said deontological, I paused because there is an option to make it ontological, deontological, whichever direction you want to go.
Views on top of a query.
But I'm seeing this potentially building not just a knowledge management system, but an alternative social media.
Of when I say social media, I mean socializing part of it through these narrow confines, the boundaries, which help build and maintain communities and becomes the knowledge base for future generations in certain archival formats.
My thought, I only think that will add is that in our journey, we will find a lot of people who would be better positioned in taking care of the parts or aspects of some things.
We need to have these things in our mind in order to be able to like, yes, we thought about this, would you like to, the delegation part has to happen because there's only a limited amount of things that you can do it right.
Think of it from the last perspective as well.
The adaptation will have to happen.
And if we are having the community support right in the right way, then the momentum would not stop.
We just need to make sure the very minimal set of ground rules or baselines that we establish the platform that we create that is in well enough order.
Yep. So that we don't have to create keep on creating the patch rules in order to like keep the system same, which is a definitive indication of a bad system when you have lots of banded fixes.
Right. Yep. So let's focus on the core aspects of things and keep on showing the seeds. That's the one important aspect that I want to talk about is that we have shown a lot of seeds.
None of those things I see as actually a failure.
I think that even if they do not come materialize the learning from them itself is a something.
But I also do think there are options or ways to rematerialize them in a in a larger cohesive system where all those things integrate into a much bigger, much larger of a platform.
Yep. All those things actually do matter. So basically what that means is we are talking of doing the things that we do best.
Answer one potential answer to your question on session one. What is worth doing for us in our context?
What is worth doing is be the protocol people is be the foundational principles.
People is be the people who build the adapter system is be the people who build ways to build the RFCs.
Yes, we don't need to write the RFCs.
No, we need to provide the basic guarantees, identify those basic guarantees that such a system has exhibited to a certain extent through some early implementations.
The implementations would change, but to identify the boundaries of such a system.
And again, the things we understand best is how do thinkers think together, how to make thinkers think together.
And I think that is the place to focus on how to make them.
Yeah. And I think that is the focus we should keep, which means if the output of Anthropic Inertia are these videos, a set of research papers or articles or blog posts at its simplest.
Let's say a blog post. Let's start with simpler with a set of documents that we prepare on how a potential community can form around this.
Let me narrow down the scope. Software provider that provides certain code libraries to build systems on top of them.
I do think we understand DevTools so well, we can reason about DevTools so well that we don't need to reason about application level building.
So let that part be the topic of next discussion and I'll set it out in a sense.
Think there is a very interesting or curious case of gravity and magnetism in a certain way.
I'll explain why.
Hey, before you go, I just wanted to check. Was this a yes or no?
Yeah, I'm just saying that we don't need to jump the gun. We need to start the platform.
But I agree that we need to be the protocol people who sets the ground rules and ponders upon whether the ground rule is set well enough or not.
And interest, that's the reason I'm extending part of the discussion in the next session.
Not disagreeing, but in order to enrich that with enough point. I just don't think I should go into that discussion right now.
I'll end up exhausting myself. I'm pretty giddy, by the way.
Like if you don't, if you're not seeing, I don't know how it's coming along, but I'm like very giddy inside.
Like that it gives me like when I came out, I had lower energy state than I'm going out with.
So anyway, so I think with that part also, we discussed before.
Point is, how do we become the magnets or the black holes where more matter feeds in?
I'm not going to I am I am not going to expand more on that today as a matter of principle for the time because yes, let's let's continue that on later.
I do. I do agree on most of like almost all the things that you said.
I just don't think we need to start with that.
Like having the expectations. I'm not certain about the order of things either.
So because I'm just saying that that those were the instances of what we can do.
Yes, on all those records, right?
I just don't think the expectations need to be the driving principle because that's what that's what ends up being the dopamine feeders.
Essentially, you need to have a dopamine blocker in a sense that we should not live on the high right on the high.
We should utilize that but not ride on it because anyways, longer discussion again.
Coming back to the point, I think we need to section our discussion in particular parts.
And I think one part should be for the next couple of weeks or next couple of months should be that how does the platform ends up forming?
What are the things that are in the should be in the to do list and how do we approach this?
Because that is going to be a massive or major part by December.
We need to have the platform ready so that we can start promoting it out and have a reveal on the New Year's kind of way.
I think that sounds very good.
And yeah, I'm like building my handbrake and pushing the brake at the same time very, very hard.
Yes, time to slow down.
Accelerator and brake at the same time.
No, no, I've left acceleration. I'm just braking. It's a momentum carrying me onto the next.
But I think this is good.
Just make a note of that topic. I think that's worth doing things.
I'm not sure how much time I'll get in the week.
But yeah, next session, we can definitely focus that focus on that.
The only reason for me to like bring out all those topics and put it in front of you is that so that it goes into your subconscious.
So basically what made me pull my handbrake so hard is that is exactly where I had started my discussions with you a few weeks back with that in mind that I want to reach that stage.
So I think like it is converging up to.
It was always going to go that way.
Like I never had a doubt.
It's just that we need to be meticulous about it.
So we can't act on dopamine heat, essentially.
That's my point. There's nothing wrong with dopamine heat.
In fact, we should utilize that.
But that should not be the driving element, because if that becomes a driving element, then chasing dopamine heat ends up becoming the actual task we end up doing and not the end result.
So basically we need to identify where do we fit in, which you already explained.
And I agree with that part and keep on doing a better job at it.
Better job at laying down the real line and not.
I know there's more fun.
I just want to put one constraint.
I just want to put one constraint.
I think whatever we think has to be thought has to be evaluated on a larger time scale than we did earlier.
And I mean, like, I don't know how long.
I don't know if it is like a 10, 12 years.
I don't know.
But the longest basically the longevity of each of those things have to be evaluated and put priority over short term gratification.
Right.
And for that matter, we need a set point rate that jump set point.
So that's the part I was going to connect with the topic that I'm not going to discuss on the next next session.
Let's let's do that.
Because having a set point is very much important and having clarity on that is very much.
Yeah.
All right. Good.
So that's pretty much it for today's session.
I'm going to go ahead and in the stream and.
